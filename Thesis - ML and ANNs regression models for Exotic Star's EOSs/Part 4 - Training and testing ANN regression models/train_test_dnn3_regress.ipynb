{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25c8f10",
   "metadata": {},
   "source": [
    "**MSc Computational Physics AUTh**<br>\n",
    "**Academic Year: 2024-2025**<br>\n",
    "**Master's Thesis**<br>\n",
    "\n",
    "**Thesis Title:**<br>  \n",
    "# **\"Reconstruction of the EoSs of Exotic Stars using ML and ANNs regression models\"**\n",
    "\n",
    "**Implemented by: Ioannis Stergakis**<br>\n",
    "**AEM: 4439**<br>\n",
    "\n",
    "**Jupyter Notebook: JN6a**<br>\n",
    "**Name: \"testing_dnn3_regress.ipynb\"**<br>\n",
    "\n",
    "**Description:**<br> \n",
    "**Training and testing `Artificial Neural Networks` with 3 middle layers for regression:**<br>\n",
    "**1. Building and compiling the networks based on the given train data**<br>\n",
    "**2. Making the learning curve of the networks**\n",
    "\n",
    "\n",
    "**Abbrevations:**<br>\n",
    "**1. NS -> Neutron Star**<br>\n",
    "**2. QS -> Quark Star**<br>\n",
    "**3. ML -> Machine Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08acbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing useful modules\n",
    "import joblib\n",
    "from data_analysis_ES_ANNs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f67db",
   "metadata": {},
   "source": [
    "# 1. Neutron Stars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9752f8d6",
   "metadata": {},
   "source": [
    "## **1.1 Using 8 M-R points**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0997bbe8",
   "metadata": {},
   "source": [
    "### A. Predicting Energy on center $E_c$ Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57f0ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists for the neurons, activation functions and dropouts in the layers of the network\n",
    "neurons_enrg_16X = [128,64,32]\n",
    "actvs_enrg_16X = [\"relu\",\"relu\",\"relu\"]\n",
    "drops_enrg_16X = [0.50,0.50,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d15f6",
   "metadata": {},
   "source": [
    "#### ->Using rowwise-shuffled data (linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69eced5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the datasets\n",
    "# regression_ANN(filename=\"linNS_reg_data_pp8mr8s100_rwshuffled.csv\",mag_reg=\"enrg\",test_ratio=0.2,val_ratio=0.2,samples_per_EOS=100).show_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "878b2930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AND ASSESSING AN ARTIFICIAL NEURAL NETWORK REGRESSION MODEL\n",
      "\n",
      "\n",
      ">Preliminaries\n",
      "===================================================================================================================\n",
      ">> DATA INFO AND SCALING:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Y (response) data type: \"enrg\"\n",
      "Number of Y columns:  12\n",
      "X (explanatory) data type: \"Mass\" and \"Radius\"\n",
      "Number of X columns:  16\n",
      "The scaling of the X (explanatory) data has been completed\n",
      "The scaling of the Y (response) data has been completed\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Compiling and fitting the model\n",
      "===================================================================================================================\n",
      ">> COMPILATION SUMMARY:\n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m396\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,804</span> (53.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,804\u001b[0m (53.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,356</span> (52.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,356\u001b[0m (52.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> TRAINING:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Ongoing fitting process...\n",
      "Epoch 1/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 41.1200 - val_loss: 35.6562\n",
      "Epoch 2/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33.0282 - val_loss: 27.1645\n",
      "Epoch 3/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26.7007 - val_loss: 21.0110\n",
      "Epoch 4/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.6946 - val_loss: 16.7444\n",
      "Epoch 5/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17.9241 - val_loss: 15.1314\n",
      "Epoch 6/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15.2427 - val_loss: 13.2624\n",
      "Epoch 7/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.3381 - val_loss: 11.8562\n",
      "Epoch 8/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.9526 - val_loss: 11.0984\n",
      "Epoch 9/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.7208 - val_loss: 10.2208\n",
      "Epoch 10/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.7986 - val_loss: 9.0452\n",
      "Epoch 11/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9002 - val_loss: 8.4442\n",
      "Epoch 12/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.2225 - val_loss: 7.8063\n",
      "Epoch 13/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6481 - val_loss: 7.3489\n",
      "Epoch 14/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.0779 - val_loss: 6.8501\n",
      "Epoch 15/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.5870 - val_loss: 6.3900\n",
      "Epoch 16/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.1144 - val_loss: 5.6583\n",
      "Epoch 17/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.7066 - val_loss: 5.4406\n",
      "Epoch 18/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3378 - val_loss: 5.0073\n",
      "Epoch 19/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0262 - val_loss: 4.7279\n",
      "Epoch 20/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6719 - val_loss: 4.6000\n",
      "Epoch 21/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4387 - val_loss: 4.1940\n",
      "Epoch 22/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1028 - val_loss: 3.8976\n",
      "Epoch 23/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8636 - val_loss: 3.6399\n",
      "Epoch 24/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6545 - val_loss: 3.3947\n",
      "Epoch 25/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.3941 - val_loss: 3.1989\n",
      "Epoch 26/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.1995 - val_loss: 2.9812\n",
      "Epoch 27/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0146 - val_loss: 2.8137\n",
      "Epoch 28/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8369 - val_loss: 2.6106\n",
      "Epoch 29/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6130 - val_loss: 2.4519\n",
      "Epoch 30/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4101 - val_loss: 2.2963\n",
      "Epoch 31/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.2725 - val_loss: 2.1550\n",
      "Epoch 32/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1335 - val_loss: 2.0229\n",
      "Epoch 33/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.9855 - val_loss: 1.9112\n",
      "Epoch 34/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8647 - val_loss: 1.7858\n",
      "Epoch 35/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7367 - val_loss: 1.6959\n",
      "Epoch 36/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6250 - val_loss: 1.5669\n",
      "Epoch 37/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5203 - val_loss: 1.4742\n",
      "Epoch 38/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4294 - val_loss: 1.3740\n",
      "Epoch 39/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3331 - val_loss: 1.3031\n",
      "Epoch 40/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2435 - val_loss: 1.2065\n",
      "Epoch 41/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1600 - val_loss: 1.1278\n",
      "Epoch 42/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0958 - val_loss: 1.0512\n",
      "Epoch 43/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0129 - val_loss: 0.9829\n",
      "Epoch 44/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9498 - val_loss: 0.9182\n",
      "Epoch 45/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8816 - val_loss: 0.8588\n",
      "Epoch 46/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8293 - val_loss: 0.8016\n",
      "Epoch 47/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7656 - val_loss: 0.7511\n",
      "Epoch 48/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7096 - val_loss: 0.6950\n",
      "Epoch 49/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6619 - val_loss: 0.6457\n",
      "Epoch 50/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6226 - val_loss: 0.6022\n",
      "Epoch 51/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5743 - val_loss: 0.5619\n",
      "Epoch 52/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5324 - val_loss: 0.5211\n",
      "Epoch 53/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4912 - val_loss: 0.4835\n",
      "Epoch 54/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4594 - val_loss: 0.4492\n",
      "Epoch 55/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4211 - val_loss: 0.4156\n",
      "Epoch 56/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3912 - val_loss: 0.3897\n",
      "Epoch 57/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3673 - val_loss: 0.3528\n",
      "Epoch 58/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3326 - val_loss: 0.3202\n",
      "Epoch 59/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3070 - val_loss: 0.3022\n",
      "Epoch 60/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2811 - val_loss: 0.2756\n",
      "Epoch 61/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2584 - val_loss: 0.2786\n",
      "Epoch 62/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2414 - val_loss: 0.2258\n",
      "Epoch 63/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2210 - val_loss: 0.2108\n",
      "Epoch 64/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2013 - val_loss: 0.1975\n",
      "Epoch 65/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1845 - val_loss: 0.1825\n",
      "Epoch 66/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1687 - val_loss: 0.1682\n",
      "Epoch 67/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1564 - val_loss: 0.1529\n",
      "Epoch 68/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1436 - val_loss: 0.1406\n",
      "Epoch 69/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1300 - val_loss: 0.1286\n",
      "Epoch 70/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1188 - val_loss: 0.1178\n",
      "Epoch 71/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1095 - val_loss: 0.1083\n",
      "Epoch 72/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0979 - val_loss: 0.0977\n",
      "Epoch 73/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0896 - val_loss: 0.0904\n",
      "Epoch 74/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0816 - val_loss: 0.0826\n",
      "Epoch 75/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0739 - val_loss: 0.0744\n",
      "Epoch 76/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0670 - val_loss: 0.0699\n",
      "Epoch 77/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0612 - val_loss: 0.0612\n",
      "Epoch 78/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0568 - val_loss: 0.0541\n",
      "Epoch 79/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0507 - val_loss: 0.0502\n",
      "Epoch 80/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0464 - val_loss: 0.0478\n",
      "Epoch 81/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0424 - val_loss: 0.0444\n",
      "Epoch 82/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0385 - val_loss: 0.0424\n",
      "Epoch 83/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0357 - val_loss: 0.0372\n",
      "Epoch 84/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0326 - val_loss: 0.0343\n",
      "Epoch 85/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0300 - val_loss: 0.0313\n",
      "Epoch 86/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0289 - val_loss: 0.0290\n",
      "Epoch 87/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0262 - val_loss: 0.0277\n",
      "Epoch 88/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0237 - val_loss: 0.0264\n",
      "Epoch 89/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0229 - val_loss: 0.0245\n",
      "Epoch 90/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0214 - val_loss: 0.0229\n",
      "Epoch 91/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0204 - val_loss: 0.0220\n",
      "Epoch 92/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0192 - val_loss: 0.0212\n",
      "Epoch 93/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0187 - val_loss: 0.0201\n",
      "Epoch 94/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0176 - val_loss: 0.0194\n",
      "Epoch 95/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0171 - val_loss: 0.0182\n",
      "Epoch 96/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - val_loss: 0.0185\n",
      "Epoch 97/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0158 - val_loss: 0.0179\n",
      "Epoch 98/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0156 - val_loss: 0.0170\n",
      "Epoch 99/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 100/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0149 - val_loss: 0.0169\n",
      "Epoch 101/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0147 - val_loss: 0.0162\n",
      "Epoch 102/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0148 - val_loss: 0.0159\n",
      "Epoch 103/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0142 - val_loss: 0.0157\n",
      "Epoch 104/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - val_loss: 0.0157\n",
      "Epoch 105/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0139 - val_loss: 0.0153\n",
      "Epoch 106/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0137 - val_loss: 0.0150\n",
      "Epoch 107/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - val_loss: 0.0150\n",
      "Epoch 108/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0148\n",
      "Epoch 109/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0132 - val_loss: 0.0143\n",
      "Epoch 110/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 111/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0140\n",
      "Epoch 112/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0127 - val_loss: 0.0138\n",
      "Epoch 113/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0135\n",
      "Epoch 114/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0132\n",
      "Epoch 115/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0121 - val_loss: 0.0129\n",
      "Epoch 116/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0117 - val_loss: 0.0126\n",
      "Epoch 117/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0126\n",
      "Epoch 118/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 119/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0120\n",
      "Epoch 120/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 121/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 122/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - val_loss: 0.0133\n",
      "Epoch 123/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 124/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 125/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 126/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 127/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 128/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 129/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 130/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 131/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - val_loss: 0.0110\n",
      "Epoch 132/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 133/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 134/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 135/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 136/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 137/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 138/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 139/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 140/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 141/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 142/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 143/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 144/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 145/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 146/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 147/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 148/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 149/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 150/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 151/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 152/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 153/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 154/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 155/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 156/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 157/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 158/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0098\n",
      "Epoch 159/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0102\n",
      "Epoch 160/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 161/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 162/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 163/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 164/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 165/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 166/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 167/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 168/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 169/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 170/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 171/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 172/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 173/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 174/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 175/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0093\n",
      "Epoch 176/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 177/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 178/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0094\n",
      "Epoch 179/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 180/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 181/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 182/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 183/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0090 - val_loss: 0.0094\n",
      "Epoch 184/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0093\n",
      "Epoch 185/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 186/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 187/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 188/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 189/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 190/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 191/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 192/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0093\n",
      "Epoch 193/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0092\n",
      "Epoch 194/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0093\n",
      "Epoch 195/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 196/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0093\n",
      "Epoch 197/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 198/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0089 - val_loss: 0.0093\n",
      "Epoch 199/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 200/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0092\n",
      "Epoch 201/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 202/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0098\n",
      "Epoch 203/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0092\n",
      "Epoch 204/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 205/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0092\n",
      "Epoch 206/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0091\n",
      "Epoch 207/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 208/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 209/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0091\n",
      "Epoch 210/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 211/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 212/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0093\n",
      "Epoch 213/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 214/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 215/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0090\n",
      "Epoch 216/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0091\n",
      "Epoch 217/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0090\n",
      "Epoch 218/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 219/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0091\n",
      "Epoch 220/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - val_loss: 0.0089\n",
      "Epoch 221/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0092\n",
      "Epoch 222/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 223/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - val_loss: 0.0090\n",
      "Epoch 224/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0089\n",
      "Epoch 225/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0091\n",
      "Epoch 226/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0090\n",
      "Epoch 227/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 228/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0089\n",
      "Epoch 229/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0089\n",
      "Epoch 230/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0089\n",
      "Epoch 231/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0088\n",
      "Epoch 232/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0089\n",
      "Epoch 233/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0089\n",
      "Epoch 234/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0089\n",
      "Epoch 235/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0088\n",
      "Epoch 236/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0086\n",
      "Epoch 237/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0088\n",
      "Epoch 238/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 239/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0088\n",
      "Epoch 240/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 241/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 242/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 243/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 244/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0086\n",
      "Epoch 245/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 246/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 247/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 248/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 249/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 250/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0088\n",
      "Epoch 251/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 252/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0086\n",
      "Epoch 253/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 254/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 255/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0089\n",
      "Epoch 256/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 257/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 258/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 259/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0108 - val_loss: 0.0086\n",
      "Epoch 260/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 261/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0086\n",
      "Epoch 262/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 263/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 264/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 265/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 266/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0085\n",
      "Epoch 267/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0085\n",
      "Epoch 268/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0090\n",
      "Epoch 269/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 270/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0085\n",
      "Epoch 271/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0084\n",
      "Epoch 272/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 273/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 274/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 275/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 276/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 277/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 278/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 279/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0084\n",
      "Epoch 280/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0085\n",
      "Epoch 281/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 282/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 283/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 284/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 285/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 286/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 287/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 288/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 289/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 290/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 291/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 292/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 293/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 294/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 295/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 296/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 297/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 298/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 299/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 300/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 301/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 302/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 303/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 304/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 305/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 306/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 307/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 308/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 309/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 310/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 311/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 312/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 313/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 314/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 315/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0080\n",
      "Epoch 316/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 317/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 318/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0085\n",
      "Epoch 319/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 320/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 321/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 322/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 323/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 324/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 325/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 326/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 327/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 328/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 329/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 330/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 331/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 332/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 333/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082\n",
      "Epoch 334/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 335/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 336/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 337/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 338/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 339/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0081\n",
      "Epoch 340/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 341/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0080\n",
      "Epoch 342/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 343/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 344/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 345/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 346/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 347/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 348/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 349/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 350/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 351/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 352/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 353/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 354/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 355/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 356/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 357/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 358/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082\n",
      "Epoch 359/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 360/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 361/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 362/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 363/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 364/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 365/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 366/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 367/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 368/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 369/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 370/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 371/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082\n",
      "Epoch 372/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 373/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 374/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 375/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 376/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 377/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 378/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082\n",
      "Epoch 379/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 380/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 381/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 382/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 383/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 384/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 385/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 386/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 387/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 388/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 389/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 390/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 391/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 392/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 393/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 394/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 395/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 396/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 397/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 398/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 399/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 400/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 401/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 402/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 403/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 404/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 405/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 406/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 407/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 408/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 409/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 410/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 411/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 412/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 413/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 414/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 415/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 416/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0078\n",
      "Epoch 417/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 418/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 419/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 420/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 421/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 422/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 423/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 424/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0082\n",
      "Epoch 425/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 426/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 427/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 428/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 429/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 430/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 431/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 432/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 433/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 434/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 435/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 436/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 437/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 438/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 439/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 440/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 441/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 442/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 443/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 444/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 445/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 446/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 447/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 448/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 449/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 450/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082\n",
      "Epoch 451/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 452/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 453/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 454/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 455/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 456/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 457/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 458/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 459/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 460/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 461/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 462/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 463/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 464/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 465/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 466/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 467/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 468/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 469/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 470/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 471/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 472/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 473/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 474/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 475/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 476/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0082\n",
      "Epoch 477/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 478/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 479/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 480/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0083\n",
      "Epoch 481/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 482/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 483/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 484/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 485/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0082\n",
      "Epoch 486/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 487/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 488/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 489/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 490/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 491/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 492/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 493/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 494/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 495/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 496/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 497/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 498/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 499/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 500/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 501/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 502/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 503/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 504/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 505/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 506/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 507/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 508/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 509/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 510/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 511/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 512/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 513/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 514/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 515/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 516/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 517/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 518/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0083\n",
      "Epoch 519/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 520/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 521/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 522/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 523/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 524/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 525/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 526/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 527/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 528/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 529/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 530/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 531/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 532/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 533/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 534/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 535/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 536/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 537/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 538/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 539/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 540/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 541/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 542/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 543/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 544/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 545/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 546/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 547/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 548/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 549/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 550/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 551/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 552/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 553/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 554/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 555/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 556/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 557/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 558/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 559/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 560/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 561/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 562/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 563/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 564/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 565/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 566/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 567/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 568/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 569/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 570/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 571/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 572/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 573/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 574/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 575/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 576/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 577/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 578/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 579/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 580/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 581/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 582/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 583/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 584/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 585/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 586/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 587/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 588/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 589/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 590/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 591/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 592/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 593/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 594/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 595/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 596/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 597/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 598/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 599/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 600/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 601/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 602/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 603/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 604/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 605/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 606/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 607/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 608/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 609/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 610/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 611/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 612/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 613/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 614/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 615/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 616/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 617/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 618/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 619/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 620/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 621/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 622/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 623/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 624/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 625/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 626/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 627/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 628/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 629/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 630/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 631/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 632/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 633/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 634/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 635/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 636/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 637/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 638/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 639/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 640/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 641/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 642/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 643/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 644/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 645/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 646/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 647/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 648/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 649/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 650/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 651/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 652/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 653/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 654/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 655/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 656/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 657/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 658/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 659/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 660/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 661/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 662/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 663/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 664/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 665/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 666/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 667/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 668/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 669/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 670/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 671/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 672/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 673/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 674/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 675/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 676/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 677/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 678/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 679/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 680/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 681/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 682/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 683/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 684/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 685/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 686/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082\n",
      "Epoch 687/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 688/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 689/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 690/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 691/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 692/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 693/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 694/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 695/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 696/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 697/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 698/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 699/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 700/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 701/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 702/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 703/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 704/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 705/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 706/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 707/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 708/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 709/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 710/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 711/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 712/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 713/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 714/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 715/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 716/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 717/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 718/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 719/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 720/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 721/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 722/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 723/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 724/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 725/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 726/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 727/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 728/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 729/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 730/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 731/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 732/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 733/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 734/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 735/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 736/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 737/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 738/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 739/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 740/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 741/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0082\n",
      "Epoch 742/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 743/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 744/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 745/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 746/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 747/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 748/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 749/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 750/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 751/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 752/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 753/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 754/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 755/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 756/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 757/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 758/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 759/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 760/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 761/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 762/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 763/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 764/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 765/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 766/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 767/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 768/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 769/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 770/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 771/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0081\n",
      "Epoch 772/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 773/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 774/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 775/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 776/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 777/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 778/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082\n",
      "Epoch 779/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 780/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 781/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 782/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 783/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 784/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 785/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 786/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 787/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 788/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0081\n",
      "Epoch 789/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 790/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 791/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 792/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 793/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 794/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 795/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 796/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 797/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 798/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 799/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 800/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 801/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 802/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 803/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 804/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 805/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 806/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 807/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 808/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 809/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 810/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 811/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 812/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 813/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 814/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 815/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 816/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 817/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 818/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 819/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 820/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 821/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 822/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 823/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 824/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 825/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 826/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 827/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 828/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 829/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 830/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 831/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 832/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 833/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 834/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 835/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 836/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 837/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082\n",
      "Epoch 838/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 839/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 840/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 841/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 842/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 843/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 844/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 845/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 846/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 847/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 848/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 849/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 850/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 851/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 852/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 853/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 854/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 855/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 856/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 857/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0081\n",
      "Epoch 858/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 859/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 860/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 861/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 862/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0082\n",
      "Epoch 863/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 864/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 865/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0082\n",
      "Epoch 866/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 867/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 868/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 869/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 870/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 871/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 872/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 873/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 874/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 875/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 876/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 877/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 878/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 879/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 880/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 881/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 882/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 883/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 884/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 885/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 886/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 887/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 888/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 889/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 890/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 891/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 892/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 893/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 894/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 895/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0081\n",
      "Epoch 896/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 897/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 898/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 899/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 900/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 901/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 902/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 903/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 904/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 905/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 906/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 907/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 908/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 909/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 910/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 911/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 912/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 913/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 914/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 915/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 916/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 917/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 918/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 919/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 920/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - val_loss: 0.0082\n",
      "Epoch 921/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 922/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 923/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 924/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 925/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 926/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 927/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - val_loss: 0.0082\n",
      "Epoch 928/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 929/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 930/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 931/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 932/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 933/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 934/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 935/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 936/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 937/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 938/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 939/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 940/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 941/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 942/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 943/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 944/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 945/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 946/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 947/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 948/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 949/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 950/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 951/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 952/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 953/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 954/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 955/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 956/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 957/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 958/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 959/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 960/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 961/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 962/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 963/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 964/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 965/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082\n",
      "Epoch 966/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 967/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 968/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 969/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 970/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 971/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 972/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 973/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 974/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 975/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 976/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 977/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 978/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 979/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 980/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 981/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 982/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 983/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 984/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 985/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 986/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 987/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 988/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 989/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 990/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 991/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 992/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 993/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 994/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 995/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 996/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 997/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0082\n",
      "Epoch 998/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 999/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 1000/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "The fitting process has been completed\n",
      "Elapsed fitting time: 4.0'39.44\"\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Overfitting metrics (using the train dataset as test dataset)\n",
      "===================================================================================================================\n",
      ">> PREDICTIONS AND REAL VALUES:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step\n",
      "Predictions of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 293.79984,  391.6806 ,  476.0228 , ..., 1393.3068 , 1530.4136 ,\n",
       "        1663.2233 ],\n",
       "       [ 288.99036,  392.85928,  486.7426 , ..., 1349.2489 , 1474.5308 ,\n",
       "        1596.3057 ],\n",
       "       [ 285.09824,  389.20215,  484.4632 , ..., 1355.7611 , 1481.2998 ,\n",
       "        1603.5131 ],\n",
       "       ...,\n",
       "       [ 220.41356,  292.19925,  374.95825, ..., 1029.8287 , 1133.2205 ,\n",
       "        1235.8774 ],\n",
       "       [ 217.97627,  288.74796,  372.19366, ..., 1030.1956 , 1133.0897 ,\n",
       "        1235.2678 ],\n",
       "       [ 224.74895,  303.2212 ,  393.8233 , ..., 1071.2509 , 1175.7594 ,\n",
       "        1279.2213 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_c(10)</th>\n",
       "      <th>E_c(25)</th>\n",
       "      <th>E_c(50)</th>\n",
       "      <th>E_c(75)</th>\n",
       "      <th>E_c(100)</th>\n",
       "      <th>E_c(200)</th>\n",
       "      <th>E_c(300)</th>\n",
       "      <th>E_c(400)</th>\n",
       "      <th>E_c(500)</th>\n",
       "      <th>E_c(600)</th>\n",
       "      <th>E_c(700)</th>\n",
       "      <th>E_c(800)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276.583390</td>\n",
       "      <td>372.852857</td>\n",
       "      <td>479.016150</td>\n",
       "      <td>557.218753</td>\n",
       "      <td>622.024504</td>\n",
       "      <td>820.705714</td>\n",
       "      <td>975.002096</td>\n",
       "      <td>1108.032300</td>\n",
       "      <td>1228.148143</td>\n",
       "      <td>1339.437507</td>\n",
       "      <td>1444.243512</td>\n",
       "      <td>1544.706350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276.583390</td>\n",
       "      <td>372.852857</td>\n",
       "      <td>479.016150</td>\n",
       "      <td>557.218753</td>\n",
       "      <td>622.024504</td>\n",
       "      <td>820.705714</td>\n",
       "      <td>975.002096</td>\n",
       "      <td>1108.032300</td>\n",
       "      <td>1228.148143</td>\n",
       "      <td>1339.437507</td>\n",
       "      <td>1444.243512</td>\n",
       "      <td>1544.706350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276.583390</td>\n",
       "      <td>372.852857</td>\n",
       "      <td>479.016150</td>\n",
       "      <td>557.218753</td>\n",
       "      <td>622.024504</td>\n",
       "      <td>820.705714</td>\n",
       "      <td>975.002096</td>\n",
       "      <td>1108.032300</td>\n",
       "      <td>1228.148143</td>\n",
       "      <td>1339.437507</td>\n",
       "      <td>1444.243512</td>\n",
       "      <td>1544.706350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276.583390</td>\n",
       "      <td>372.852857</td>\n",
       "      <td>479.016150</td>\n",
       "      <td>557.218753</td>\n",
       "      <td>622.024504</td>\n",
       "      <td>820.705714</td>\n",
       "      <td>975.002096</td>\n",
       "      <td>1108.032300</td>\n",
       "      <td>1228.148143</td>\n",
       "      <td>1339.437507</td>\n",
       "      <td>1444.243512</td>\n",
       "      <td>1544.706350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276.583390</td>\n",
       "      <td>372.852857</td>\n",
       "      <td>479.016150</td>\n",
       "      <td>557.218753</td>\n",
       "      <td>622.024504</td>\n",
       "      <td>820.705714</td>\n",
       "      <td>975.002096</td>\n",
       "      <td>1108.032300</td>\n",
       "      <td>1228.148143</td>\n",
       "      <td>1339.437507</td>\n",
       "      <td>1444.243512</td>\n",
       "      <td>1544.706350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19395</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945996</td>\n",
       "      <td>1029.945996</td>\n",
       "      <td>1129.945996</td>\n",
       "      <td>1229.945996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19396</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945996</td>\n",
       "      <td>1029.945996</td>\n",
       "      <td>1129.945996</td>\n",
       "      <td>1229.945996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19397</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945996</td>\n",
       "      <td>1029.945996</td>\n",
       "      <td>1129.945996</td>\n",
       "      <td>1229.945996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19398</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945996</td>\n",
       "      <td>1029.945996</td>\n",
       "      <td>1129.945996</td>\n",
       "      <td>1229.945996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19399</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945996</td>\n",
       "      <td>1029.945996</td>\n",
       "      <td>1129.945996</td>\n",
       "      <td>1229.945996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19400 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          E_c(10)     E_c(25)     E_c(50)     E_c(75)    E_c(100)    E_c(200)  \\\n",
       "0      276.583390  372.852857  479.016150  557.218753  622.024504  820.705714   \n",
       "1      276.583390  372.852857  479.016150  557.218753  622.024504  820.705714   \n",
       "2      276.583390  372.852857  479.016150  557.218753  622.024504  820.705714   \n",
       "3      276.583390  372.852857  479.016150  557.218753  622.024504  820.705714   \n",
       "4      276.583390  372.852857  479.016150  557.218753  622.024504  820.705714   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "19395  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "19396  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "19397  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "19398  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "19399  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "\n",
       "         E_c(300)     E_c(400)     E_c(500)     E_c(600)     E_c(700)  \\\n",
       "0      975.002096  1108.032300  1228.148143  1339.437507  1444.243512   \n",
       "1      975.002096  1108.032300  1228.148143  1339.437507  1444.243512   \n",
       "2      975.002096  1108.032300  1228.148143  1339.437507  1444.243512   \n",
       "3      975.002096  1108.032300  1228.148143  1339.437507  1444.243512   \n",
       "4      975.002096  1108.032300  1228.148143  1339.437507  1444.243512   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "19395  722.015264   829.584262   929.945996  1029.945996  1129.945996   \n",
       "19396  722.015264   829.584262   929.945996  1029.945996  1129.945996   \n",
       "19397  722.015264   829.584262   929.945996  1029.945996  1129.945996   \n",
       "19398  722.015264   829.584262   929.945996  1029.945996  1129.945996   \n",
       "19399  722.015264   829.584262   929.945996  1029.945996  1129.945996   \n",
       "\n",
       "          E_c(800)  \n",
       "0      1544.706350  \n",
       "1      1544.706350  \n",
       "2      1544.706350  \n",
       "3      1544.706350  \n",
       "4      1544.706350  \n",
       "...            ...  \n",
       "19395  1229.945996  \n",
       "19396  1229.945996  \n",
       "19397  1229.945996  \n",
       "19398  1229.945996  \n",
       "19399  1229.945996  \n",
       "\n",
       "[19400 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED LOG ERROR (MSLE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[0.00754999 0.00579417 0.00431228 0.00363256 0.00388046 0.00249479\n",
      " 0.00210805 0.00242953 0.00352013 0.00501896 0.00662251 0.00818348]\n",
      "Uniform average\n",
      "0.004628907804036779\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED ERROR (MSE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[ 1009.04281514  1478.96672521  1617.77231876  1807.93510495\n",
      "  2273.99373537  2391.52565821  2700.25920468  4078.95431668\n",
      "  7708.32114345 14022.89326169 23290.12917801 35673.52218621]\n",
      "Uniform average\n",
      "8171.10963736349\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Prediction metrics (using the actual test dataset)\n",
      "===================================================================================================================\n",
      ">> PREDICTIONS AND REAL VALUES:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step\n",
      "Predictions of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 216.53859,  282.94675,  362.0314 , ..., 1011.1836 , 1114.3414 ,\n",
       "        1216.6915 ],\n",
       "       [ 217.33717,  285.60236,  363.63922, ..., 1004.3376 , 1106.6084 ,\n",
       "        1208.5051 ],\n",
       "       [ 219.24957,  289.8174 ,  367.4613 , ..., 1002.83813, 1104.7666 ,\n",
       "        1206.6031 ],\n",
       "       ...,\n",
       "       [ 289.64487,  406.41913,  513.75867, ..., 1304.9258 , 1412.9429 ,\n",
       "        1518.8845 ],\n",
       "       [ 277.9032 ,  385.5553 ,  488.20718, ..., 1390.7078 , 1514.3195 ,\n",
       "        1634.5933 ],\n",
       "       [ 290.25702,  403.2559 ,  505.70804, ..., 1247.1904 , 1352.9786 ,\n",
       "        1457.7074 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_c(10)</th>\n",
       "      <th>E_c(25)</th>\n",
       "      <th>E_c(50)</th>\n",
       "      <th>E_c(75)</th>\n",
       "      <th>E_c(100)</th>\n",
       "      <th>E_c(200)</th>\n",
       "      <th>E_c(300)</th>\n",
       "      <th>E_c(400)</th>\n",
       "      <th>E_c(500)</th>\n",
       "      <th>E_c(600)</th>\n",
       "      <th>E_c(700)</th>\n",
       "      <th>E_c(800)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24200</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945992</td>\n",
       "      <td>1029.945992</td>\n",
       "      <td>1129.945992</td>\n",
       "      <td>1229.945992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24201</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945992</td>\n",
       "      <td>1029.945992</td>\n",
       "      <td>1129.945992</td>\n",
       "      <td>1229.945992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24202</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945992</td>\n",
       "      <td>1029.945992</td>\n",
       "      <td>1129.945992</td>\n",
       "      <td>1229.945992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24203</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945992</td>\n",
       "      <td>1029.945992</td>\n",
       "      <td>1129.945992</td>\n",
       "      <td>1229.945992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24204</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945992</td>\n",
       "      <td>1029.945992</td>\n",
       "      <td>1129.945992</td>\n",
       "      <td>1229.945992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30295</th>\n",
       "      <td>284.859202</td>\n",
       "      <td>439.667175</td>\n",
       "      <td>529.611941</td>\n",
       "      <td>592.667261</td>\n",
       "      <td>643.331503</td>\n",
       "      <td>811.114901</td>\n",
       "      <td>964.023356</td>\n",
       "      <td>1095.948633</td>\n",
       "      <td>1215.131408</td>\n",
       "      <td>1325.605161</td>\n",
       "      <td>1429.681834</td>\n",
       "      <td>1529.890602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30296</th>\n",
       "      <td>284.859202</td>\n",
       "      <td>439.667175</td>\n",
       "      <td>529.611941</td>\n",
       "      <td>592.667261</td>\n",
       "      <td>643.331503</td>\n",
       "      <td>811.114901</td>\n",
       "      <td>964.023356</td>\n",
       "      <td>1095.948633</td>\n",
       "      <td>1215.131408</td>\n",
       "      <td>1325.605161</td>\n",
       "      <td>1429.681834</td>\n",
       "      <td>1529.890602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30297</th>\n",
       "      <td>284.859202</td>\n",
       "      <td>439.667175</td>\n",
       "      <td>529.611941</td>\n",
       "      <td>592.667261</td>\n",
       "      <td>643.331503</td>\n",
       "      <td>811.114901</td>\n",
       "      <td>964.023356</td>\n",
       "      <td>1095.948633</td>\n",
       "      <td>1215.131408</td>\n",
       "      <td>1325.605161</td>\n",
       "      <td>1429.681834</td>\n",
       "      <td>1529.890602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30298</th>\n",
       "      <td>284.859202</td>\n",
       "      <td>439.667175</td>\n",
       "      <td>529.611941</td>\n",
       "      <td>592.667261</td>\n",
       "      <td>643.331503</td>\n",
       "      <td>811.114901</td>\n",
       "      <td>964.023356</td>\n",
       "      <td>1095.948633</td>\n",
       "      <td>1215.131408</td>\n",
       "      <td>1325.605161</td>\n",
       "      <td>1429.681834</td>\n",
       "      <td>1529.890602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30299</th>\n",
       "      <td>284.859202</td>\n",
       "      <td>439.667175</td>\n",
       "      <td>529.611941</td>\n",
       "      <td>592.667261</td>\n",
       "      <td>643.331503</td>\n",
       "      <td>811.114901</td>\n",
       "      <td>964.023356</td>\n",
       "      <td>1095.948633</td>\n",
       "      <td>1215.131408</td>\n",
       "      <td>1325.605161</td>\n",
       "      <td>1429.681834</td>\n",
       "      <td>1529.890602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          E_c(10)     E_c(25)     E_c(50)     E_c(75)    E_c(100)    E_c(200)  \\\n",
       "24200  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "24201  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "24202  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "24203  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "24204  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "30295  284.859202  439.667175  529.611941  592.667261  643.331503  811.114901   \n",
       "30296  284.859202  439.667175  529.611941  592.667261  643.331503  811.114901   \n",
       "30297  284.859202  439.667175  529.611941  592.667261  643.331503  811.114901   \n",
       "30298  284.859202  439.667175  529.611941  592.667261  643.331503  811.114901   \n",
       "30299  284.859202  439.667175  529.611941  592.667261  643.331503  811.114901   \n",
       "\n",
       "         E_c(300)     E_c(400)     E_c(500)     E_c(600)     E_c(700)  \\\n",
       "24200  722.015264   829.584262   929.945992  1029.945992  1129.945992   \n",
       "24201  722.015264   829.584262   929.945992  1029.945992  1129.945992   \n",
       "24202  722.015264   829.584262   929.945992  1029.945992  1129.945992   \n",
       "24203  722.015264   829.584262   929.945992  1029.945992  1129.945992   \n",
       "24204  722.015264   829.584262   929.945992  1029.945992  1129.945992   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "30295  964.023356  1095.948633  1215.131408  1325.605161  1429.681834   \n",
       "30296  964.023356  1095.948633  1215.131408  1325.605161  1429.681834   \n",
       "30297  964.023356  1095.948633  1215.131408  1325.605161  1429.681834   \n",
       "30298  964.023356  1095.948633  1215.131408  1325.605161  1429.681834   \n",
       "30299  964.023356  1095.948633  1215.131408  1325.605161  1429.681834   \n",
       "\n",
       "          E_c(800)  \n",
       "24200  1229.945992  \n",
       "24201  1229.945992  \n",
       "24202  1229.945992  \n",
       "24203  1229.945992  \n",
       "24204  1229.945992  \n",
       "...            ...  \n",
       "30295  1529.890602  \n",
       "30296  1529.890602  \n",
       "30297  1529.890602  \n",
       "30298  1529.890602  \n",
       "30299  1529.890602  \n",
       "\n",
       "[6100 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED LOG ERROR (MSLE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[0.00665329 0.00625499 0.00514682 0.00436565 0.00505273 0.00355263\n",
      " 0.00351613 0.00419671 0.00548621 0.00758292 0.00989924 0.01218857]\n",
      "Uniform average\n",
      "0.006157990303682946\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED ERROR (MSE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[  948.63911672  1727.51781937  1707.82501919  1866.81041511\n",
      "  2676.36349305  3069.57933358  4081.37222906  6474.19488356\n",
      " 10493.63718759 17016.66618843 26297.89682619 38522.52356086]\n",
      "Uniform average\n",
      "9573.585506059897\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Learning curve\n",
      "===================================================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Saving the ANN model info:\n",
      "===================================================================================================================\n",
      "The ANNs model info have been saved in the \"linNS_dnn3_enrg_16X_rwsh.pkl\" file !!!\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Building a regression ANN model\n",
    "regression_ANN(\"linNS_reg_data_pp8mr8s100_rwshuffled.csv\",mag_reg=\"enrg\",test_ratio=0.2,val_ratio=0.2,samples_per_EOS=100).train_model(\"no\",neurons_enrg_16X,actvs_enrg_16X,drops_enrg_16X,adam_learn_rate=1e-3,train_epochs=1000,batch_size=128,filesave=\"linNS_dnn3_enrg_16X_rwsh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0a951e",
   "metadata": {},
   "source": [
    "## **1.2 Using 16 M-R points**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54f424",
   "metadata": {},
   "source": [
    "### A. Predicting Energy on center $E_c$ Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a7cf489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists for the neurons, activation functions and dropouts in the layers of the network\n",
    "neurons_enrg_32X = [128,64,32]\n",
    "actvs_enrg_32X = [\"relu\",\"relu\",\"relu\"]\n",
    "drops_enrg_32X = [0.5,0.5,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb67ff3d",
   "metadata": {},
   "source": [
    "#### ->Using rowwise-shuffled data (linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17a598a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the datasets\n",
    "# regression_ANN(filename=\"linNS_reg_data_pp8mr16s100_rwshuffled.csv\",mag_reg=\"enrg\",test_ratio=0.2,val_ratio=0.2,samples_per_EOS=100).show_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "809d4296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AND ASSESSING AN ARTIFICIAL NEURAL NETWORK REGRESSION MODEL\n",
      "\n",
      "\n",
      ">Preliminaries\n",
      "===================================================================================================================\n",
      ">> DATA INFO AND SCALING:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Y (response) data type: \"enrg\"\n",
      "Number of Y columns:  12\n",
      "X (explanatory) data type: \"Mass\" and \"Radius\"\n",
      "Number of X columns:  32\n",
      "The scaling of the X (explanatory) data has been completed\n",
      "The scaling of the Y (response) data has been completed\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Compiling and fitting the model\n",
      "===================================================================================================================\n",
      ">> COMPILATION SUMMARY:\n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m396\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,852</span> (61.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,852\u001b[0m (61.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,404</span> (60.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,404\u001b[0m (60.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> TRAINING:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Ongoing fitting process...\n",
      "Epoch 1/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 41.1089 - val_loss: 36.4235\n",
      "Epoch 2/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32.7838 - val_loss: 26.4190\n",
      "Epoch 3/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26.4302 - val_loss: 21.4115\n",
      "Epoch 4/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.7741 - val_loss: 17.6270\n",
      "Epoch 5/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17.8084 - val_loss: 15.1305\n",
      "Epoch 6/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15.3336 - val_loss: 13.8870\n",
      "Epoch 7/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.4854 - val_loss: 12.2405\n",
      "Epoch 8/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.0128 - val_loss: 10.8068\n",
      "Epoch 9/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.8891 - val_loss: 10.0141\n",
      "Epoch 10/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.8904 - val_loss: 9.4169\n",
      "Epoch 11/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.0451 - val_loss: 8.4685\n",
      "Epoch 12/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.3704 - val_loss: 7.7188\n",
      "Epoch 13/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.7827 - val_loss: 7.0120\n",
      "Epoch 14/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.2803 - val_loss: 6.6012\n",
      "Epoch 15/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.7383 - val_loss: 6.1237\n",
      "Epoch 16/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.3609 - val_loss: 5.7492\n",
      "Epoch 17/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.9109 - val_loss: 5.3490\n",
      "Epoch 18/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4606 - val_loss: 5.0811\n",
      "Epoch 19/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1107 - val_loss: 4.7854\n",
      "Epoch 20/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7724 - val_loss: 4.3903\n",
      "Epoch 21/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4808 - val_loss: 4.1176\n",
      "Epoch 22/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1816 - val_loss: 3.9310\n",
      "Epoch 23/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9661 - val_loss: 3.6611\n",
      "Epoch 24/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7513 - val_loss: 3.4170\n",
      "Epoch 25/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4642 - val_loss: 3.2127\n",
      "Epoch 26/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.2114 - val_loss: 3.0070\n",
      "Epoch 27/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.9867 - val_loss: 2.8191\n",
      "Epoch 28/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7947 - val_loss: 2.6609\n",
      "Epoch 29/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.6354 - val_loss: 2.4917\n",
      "Epoch 30/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.4659 - val_loss: 2.3274\n",
      "Epoch 31/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.3096 - val_loss: 2.2013\n",
      "Epoch 32/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.1356 - val_loss: 2.0562\n",
      "Epoch 33/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2.0102 - val_loss: 1.9311\n",
      "Epoch 34/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.8987 - val_loss: 1.7995\n",
      "Epoch 35/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.7831 - val_loss: 1.6878\n",
      "Epoch 36/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.6556 - val_loss: 1.5831\n",
      "Epoch 37/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.5428 - val_loss: 1.4832\n",
      "Epoch 38/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.4509 - val_loss: 1.3913\n",
      "Epoch 39/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.3493 - val_loss: 1.2961\n",
      "Epoch 40/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.2605 - val_loss: 1.2162\n",
      "Epoch 41/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1908 - val_loss: 1.1339\n",
      "Epoch 42/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1069 - val_loss: 1.0589\n",
      "Epoch 43/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0281 - val_loss: 0.9828\n",
      "Epoch 44/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9590 - val_loss: 0.9202\n",
      "Epoch 45/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8973 - val_loss: 0.8586\n",
      "Epoch 46/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8344 - val_loss: 0.8018\n",
      "Epoch 47/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7731 - val_loss: 0.7474\n",
      "Epoch 48/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7199 - val_loss: 0.6996\n",
      "Epoch 49/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6655 - val_loss: 0.6480\n",
      "Epoch 50/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6221 - val_loss: 0.6122\n",
      "Epoch 51/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5805 - val_loss: 0.5556\n",
      "Epoch 52/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5355 - val_loss: 0.5178\n",
      "Epoch 53/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4930 - val_loss: 0.4830\n",
      "Epoch 54/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4558 - val_loss: 0.4472\n",
      "Epoch 55/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4262 - val_loss: 0.4126\n",
      "Epoch 56/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3966 - val_loss: 0.3846\n",
      "Epoch 57/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3631 - val_loss: 0.3560\n",
      "Epoch 58/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3407 - val_loss: 0.3295\n",
      "Epoch 59/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3068 - val_loss: 0.3057\n",
      "Epoch 60/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2845 - val_loss: 0.2787\n",
      "Epoch 61/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2618 - val_loss: 0.2577\n",
      "Epoch 62/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2395 - val_loss: 0.2371\n",
      "Epoch 63/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2195 - val_loss: 0.2209\n",
      "Epoch 64/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.2025 - val_loss: 0.2011\n",
      "Epoch 65/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1832 - val_loss: 0.1857\n",
      "Epoch 66/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1681 - val_loss: 0.1711\n",
      "Epoch 67/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1585 - val_loss: 0.1714\n",
      "Epoch 68/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1426 - val_loss: 0.1410\n",
      "Epoch 69/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1288 - val_loss: 0.1311\n",
      "Epoch 70/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1176 - val_loss: 0.1188\n",
      "Epoch 71/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1075 - val_loss: 0.1100\n",
      "Epoch 72/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0986 - val_loss: 0.1002\n",
      "Epoch 73/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0903 - val_loss: 0.0905\n",
      "Epoch 74/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0824 - val_loss: 0.0827\n",
      "Epoch 75/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0745 - val_loss: 0.0756\n",
      "Epoch 76/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0672 - val_loss: 0.0692\n",
      "Epoch 77/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0614 - val_loss: 0.0625\n",
      "Epoch 78/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0556 - val_loss: 0.0588\n",
      "Epoch 79/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0515 - val_loss: 0.0543\n",
      "Epoch 80/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0469 - val_loss: 0.0472\n",
      "Epoch 81/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0417 - val_loss: 0.0422\n",
      "Epoch 82/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0392 - val_loss: 0.0395\n",
      "Epoch 83/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0350 - val_loss: 0.0364\n",
      "Epoch 84/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0328 - val_loss: 0.0331\n",
      "Epoch 85/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0297 - val_loss: 0.0308\n",
      "Epoch 86/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 87/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0258 - val_loss: 0.0272\n",
      "Epoch 88/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0240 - val_loss: 0.0259\n",
      "Epoch 89/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0226 - val_loss: 0.0239\n",
      "Epoch 90/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0215 - val_loss: 0.0228\n",
      "Epoch 91/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0201 - val_loss: 0.0209\n",
      "Epoch 92/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0187 - val_loss: 0.0204\n",
      "Epoch 93/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0177 - val_loss: 0.0192\n",
      "Epoch 94/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0171 - val_loss: 0.0190\n",
      "Epoch 95/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0165 - val_loss: 0.0181\n",
      "Epoch 96/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - val_loss: 0.0174\n",
      "Epoch 97/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0153 - val_loss: 0.0165\n",
      "Epoch 98/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0146 - val_loss: 0.0162\n",
      "Epoch 99/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - val_loss: 0.0159\n",
      "Epoch 100/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0141 - val_loss: 0.0153\n",
      "Epoch 101/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - val_loss: 0.0151\n",
      "Epoch 102/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0128 - val_loss: 0.0143\n",
      "Epoch 103/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0129 - val_loss: 0.0140\n",
      "Epoch 104/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0125 - val_loss: 0.0136\n",
      "Epoch 105/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0125 - val_loss: 0.0133\n",
      "Epoch 106/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0122 - val_loss: 0.0129\n",
      "Epoch 107/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 108/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0126\n",
      "Epoch 109/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 110/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 111/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 112/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 113/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 114/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 115/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 116/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0128 - val_loss: 0.0111\n",
      "Epoch 117/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 118/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 119/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 120/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 121/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 122/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 123/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 124/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 125/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 126/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 127/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 128/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 129/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 130/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 131/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 132/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 133/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 134/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 135/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 136/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 137/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 138/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 139/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 140/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 141/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 142/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0133 - val_loss: 0.0099\n",
      "Epoch 143/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - val_loss: 0.0095\n",
      "Epoch 144/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 145/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 146/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 147/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 148/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092 - val_loss: 0.0094\n",
      "Epoch 149/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 150/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - val_loss: 0.0093\n",
      "Epoch 151/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0091 - val_loss: 0.0093\n",
      "Epoch 152/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 153/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 154/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0092\n",
      "Epoch 155/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 156/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0092\n",
      "Epoch 157/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 158/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 159/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0094 - val_loss: 0.0090\n",
      "Epoch 160/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 161/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 162/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0090\n",
      "Epoch 163/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0088\n",
      "Epoch 164/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 165/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 166/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 167/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0090\n",
      "Epoch 168/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0089\n",
      "Epoch 169/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 170/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0093 - val_loss: 0.0090\n",
      "Epoch 171/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - val_loss: 0.0091\n",
      "Epoch 172/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0090\n",
      "Epoch 173/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0089 - val_loss: 0.0090\n",
      "Epoch 174/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 175/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 176/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0088\n",
      "Epoch 177/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0088\n",
      "Epoch 178/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0086 - val_loss: 0.0089\n",
      "Epoch 179/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - val_loss: 0.0089\n",
      "Epoch 180/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0088\n",
      "Epoch 181/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 182/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 183/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - val_loss: 0.0088\n",
      "Epoch 184/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0084 - val_loss: 0.0089\n",
      "Epoch 185/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0088\n",
      "Epoch 186/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0087\n",
      "Epoch 187/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0089\n",
      "Epoch 188/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0087\n",
      "Epoch 189/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 190/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0086\n",
      "Epoch 191/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 192/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0153 - val_loss: 0.0085\n",
      "Epoch 193/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 194/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 195/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 196/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0087\n",
      "Epoch 197/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 198/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 199/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 200/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 201/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 202/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0105 - val_loss: 0.0085\n",
      "Epoch 203/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 204/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 205/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 206/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 207/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 208/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 209/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 210/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0085\n",
      "Epoch 211/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 212/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 213/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 214/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0084 - val_loss: 0.0086\n",
      "Epoch 215/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 216/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 217/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0086\n",
      "Epoch 218/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 219/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 220/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - val_loss: 0.0085\n",
      "Epoch 221/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 222/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 223/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 224/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 225/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 226/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - val_loss: 0.0083\n",
      "Epoch 227/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 228/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 229/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 230/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0092\n",
      "Epoch 231/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0083\n",
      "Epoch 232/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 233/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 234/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 235/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 236/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 237/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 238/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0082\n",
      "Epoch 239/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 240/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0076 - val_loss: 0.0082\n",
      "Epoch 241/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 242/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 243/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 244/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 245/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 246/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 247/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0081\n",
      "Epoch 248/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 249/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 250/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 251/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0080\n",
      "Epoch 252/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0083\n",
      "Epoch 253/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 254/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0083\n",
      "Epoch 255/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0083\n",
      "Epoch 256/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 257/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 258/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 259/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0081\n",
      "Epoch 260/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 261/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 262/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 263/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 264/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 265/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0080\n",
      "Epoch 266/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 267/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 268/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 269/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 270/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 271/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0084\n",
      "Epoch 272/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0082\n",
      "Epoch 273/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 274/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 275/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - val_loss: 0.0080\n",
      "Epoch 276/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 277/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 278/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 279/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0082\n",
      "Epoch 280/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0090\n",
      "Epoch 281/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 282/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 283/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 284/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 285/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0081\n",
      "Epoch 286/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 287/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 288/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 289/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 290/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 291/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 292/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 293/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 294/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 295/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 296/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 297/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - val_loss: 0.0079\n",
      "Epoch 298/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 299/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 300/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 301/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 302/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 303/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 304/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 305/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 306/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 307/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 308/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 309/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 310/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 311/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 312/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 313/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 314/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 315/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 316/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 317/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 318/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 319/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 320/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 321/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 322/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 323/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 324/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 325/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 326/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 327/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 328/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 329/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 330/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 331/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 332/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 333/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 334/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 335/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 336/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 337/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 338/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 339/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 340/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 341/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 342/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 343/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 344/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 345/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 346/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 347/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 348/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 349/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 350/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 351/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 352/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 353/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 354/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 355/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 356/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 357/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 358/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 359/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 360/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 361/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 362/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 363/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 364/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 365/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 366/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 367/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 368/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0078\n",
      "Epoch 369/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0094 - val_loss: 0.0076\n",
      "Epoch 370/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 371/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 372/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 373/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 374/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 375/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0076\n",
      "Epoch 376/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 377/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0104 - val_loss: 0.0077\n",
      "Epoch 378/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 379/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 380/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 381/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 382/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 383/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 384/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 385/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 386/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 387/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 388/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 389/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - val_loss: 0.0077\n",
      "Epoch 390/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 391/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 392/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 393/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 394/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 395/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 396/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 397/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 398/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 399/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 400/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 401/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 402/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 403/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 404/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 405/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 406/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 407/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 408/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 409/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 410/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 411/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 412/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 413/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 414/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 415/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 416/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 417/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 418/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 419/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 420/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 421/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 422/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 423/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 424/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 425/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 426/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 427/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 428/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 429/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 430/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 431/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 432/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 433/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 434/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 435/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 436/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 437/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 438/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 439/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 440/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 441/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 442/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 443/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 444/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 445/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 446/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 447/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 448/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 449/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 450/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 451/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 452/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 453/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 454/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 455/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 456/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 457/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 458/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 459/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 460/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 461/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 462/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 463/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 464/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 465/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 466/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 467/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 468/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 469/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 470/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 471/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 472/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 473/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 474/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 475/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 476/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 477/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 478/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 479/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 480/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0075\n",
      "Epoch 481/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 482/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 483/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 484/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 485/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 486/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 487/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 488/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 489/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 490/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 491/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 492/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 493/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 494/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 495/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 496/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 497/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 498/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 499/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 500/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 501/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 502/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 503/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 504/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 505/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 506/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 507/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 508/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 509/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 510/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 511/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 512/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 513/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 514/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 515/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 516/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 517/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 518/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 519/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 520/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 521/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 522/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 523/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 524/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 525/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 526/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 527/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 528/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 529/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 530/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 531/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 532/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 533/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 534/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 535/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 536/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 537/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 538/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 539/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 540/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 541/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 542/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 543/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 544/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 545/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 546/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 547/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 548/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 549/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 550/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 551/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 552/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 553/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 554/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 555/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 556/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 557/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 558/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 559/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 560/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 561/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 562/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 563/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 564/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 565/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 566/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 567/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 568/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 569/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 570/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 571/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 572/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 573/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 574/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 575/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 576/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 577/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 578/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 579/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 580/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 581/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 582/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 583/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 584/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 585/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 586/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 587/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 588/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 589/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 590/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 591/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 592/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 593/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 594/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 595/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 596/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 597/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 598/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 599/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 600/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 601/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 602/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 603/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 604/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 605/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 606/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 607/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 608/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0070 - val_loss: 0.0077\n",
      "Epoch 609/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 610/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 611/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 612/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 613/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 614/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 615/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 616/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 617/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 618/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 619/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 620/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 621/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 622/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 623/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 624/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 625/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 626/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 627/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 628/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 629/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 630/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 631/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 632/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 633/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 634/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 635/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 636/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 637/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 638/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 639/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 640/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 641/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 642/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 643/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 644/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 645/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 646/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 647/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 648/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 649/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 650/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 651/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 652/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 653/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 654/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 655/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 656/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 657/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 658/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 659/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 660/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 661/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 662/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 663/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 664/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 665/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 666/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 667/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 668/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 669/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 670/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 671/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 672/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 673/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 674/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 675/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 676/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 677/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 678/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 679/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 680/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 681/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 682/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 683/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 684/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 685/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 686/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 687/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 688/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 689/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 690/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 691/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 692/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 693/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 694/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 695/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 696/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 697/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 698/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 699/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 700/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 701/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 702/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 703/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 704/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 705/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 706/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 707/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 708/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 709/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 710/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 711/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 712/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 713/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 714/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 715/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 716/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 717/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 718/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 719/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 720/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 721/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 722/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 723/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 724/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 725/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 726/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 727/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 728/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 729/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 730/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 731/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 732/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 733/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 734/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 735/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 736/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 737/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 738/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 739/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 740/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 741/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 742/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 743/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 744/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 745/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 746/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 747/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 748/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 749/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 750/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 751/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 752/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 753/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 754/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 755/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 756/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 757/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 758/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 759/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 760/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 761/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 762/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 763/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 764/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 765/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 766/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 767/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 768/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 769/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 770/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 771/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 772/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 773/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 774/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 775/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 776/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 777/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 778/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 779/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 780/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 781/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 782/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 783/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 784/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 785/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 786/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 787/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 788/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 789/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 790/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 791/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 792/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 793/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 794/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 795/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 796/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 797/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 798/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 799/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 800/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 801/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 802/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 803/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 804/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 805/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 806/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 807/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0078\n",
      "Epoch 808/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 809/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 810/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 811/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 812/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 813/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 814/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 815/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 816/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 817/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 818/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 819/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 820/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 821/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 822/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 823/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 824/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 825/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 826/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 827/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 828/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 829/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 830/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 831/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0078\n",
      "Epoch 832/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 833/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 834/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 835/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 836/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 837/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 838/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 839/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 840/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 841/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 842/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 843/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 844/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 845/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 846/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 847/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 848/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 849/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 850/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 851/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 852/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 853/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0078\n",
      "Epoch 854/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 855/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 856/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 857/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 858/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 859/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 860/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 861/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 862/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 863/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 864/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 865/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 866/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 867/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 868/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 869/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 870/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 871/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 872/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 873/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 874/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 875/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 876/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 877/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 878/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 879/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 880/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 881/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 882/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 883/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 884/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 885/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 886/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 887/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 888/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 889/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 890/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 891/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 892/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 893/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 894/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 895/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 896/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 897/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0078\n",
      "Epoch 898/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 899/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 900/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 901/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 902/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 903/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 904/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 905/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 906/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 907/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 908/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 909/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 910/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 911/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 912/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 913/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 914/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 915/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 916/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 917/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 918/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 919/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 920/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 921/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 922/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 923/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 924/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 925/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 926/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 927/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 928/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 929/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 930/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 931/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 932/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 933/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 934/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 935/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 936/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 937/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 938/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 939/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 940/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 941/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 942/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 943/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 944/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 945/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 946/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 947/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 948/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 949/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 950/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 951/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 952/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 953/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 954/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 955/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 956/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 957/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 958/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 959/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 960/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 961/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 962/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 963/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 964/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 965/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 966/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 967/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 968/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 969/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 970/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 971/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 972/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 973/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 974/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 975/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 976/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 977/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 978/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 979/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 980/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 981/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 982/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 983/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 984/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 985/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 986/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 987/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 988/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 989/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 990/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 991/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 992/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 993/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 994/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 995/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0077\n",
      "Epoch 996/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 997/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 998/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 999/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 1000/1000\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "The fitting process has been completed\n",
      "Elapsed fitting time: 5.0'1.05\"\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Overfitting metrics (using the train dataset as test dataset)\n",
      "===================================================================================================================\n",
      ">> PREDICTIONS AND REAL VALUES:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m607/607\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step\n",
      "Predictions of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 278.41913,  384.38052,  485.38806, ..., 1331.3806 , 1454.2267 ,\n",
       "        1572.0482 ],\n",
       "       [ 280.1079 ,  377.62103,  469.48718, ..., 1455.6243 , 1600.0502 ,\n",
       "        1739.8762 ],\n",
       "       [ 279.02658,  379.83194,  475.25305, ..., 1449.1542 , 1589.9635 ,\n",
       "        1725.8234 ],\n",
       "       ...,\n",
       "       [ 218.10706,  286.0512 ,  362.8926 , ...,  995.9751 , 1096.8857 ,\n",
       "        1197.0538 ],\n",
       "       [ 209.35693,  279.193  ,  363.52954, ..., 1016.818  , 1116.363  ,\n",
       "        1214.9573 ],\n",
       "       [ 209.10016,  274.94003,  353.33844, ...,  990.4047 , 1090.475  ,\n",
       "        1189.5166 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_c(10)</th>\n",
       "      <th>E_c(25)</th>\n",
       "      <th>E_c(50)</th>\n",
       "      <th>E_c(75)</th>\n",
       "      <th>E_c(100)</th>\n",
       "      <th>E_c(200)</th>\n",
       "      <th>E_c(300)</th>\n",
       "      <th>E_c(400)</th>\n",
       "      <th>E_c(500)</th>\n",
       "      <th>E_c(600)</th>\n",
       "      <th>E_c(700)</th>\n",
       "      <th>E_c(800)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276.583390</td>\n",
       "      <td>372.852857</td>\n",
       "      <td>479.016150</td>\n",
       "      <td>557.218753</td>\n",
       "      <td>622.024504</td>\n",
       "      <td>820.705714</td>\n",
       "      <td>975.002096</td>\n",
       "      <td>1108.032300</td>\n",
       "      <td>1228.148143</td>\n",
       "      <td>1339.437507</td>\n",
       "      <td>1444.243512</td>\n",
       "      <td>1544.706350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276.583390</td>\n",
       "      <td>372.852857</td>\n",
       "      <td>479.016150</td>\n",
       "      <td>557.218753</td>\n",
       "      <td>622.024504</td>\n",
       "      <td>820.705714</td>\n",
       "      <td>975.002096</td>\n",
       "      <td>1108.032300</td>\n",
       "      <td>1228.148143</td>\n",
       "      <td>1339.437507</td>\n",
       "      <td>1444.243512</td>\n",
       "      <td>1544.706350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276.583390</td>\n",
       "      <td>372.852857</td>\n",
       "      <td>479.016150</td>\n",
       "      <td>557.218753</td>\n",
       "      <td>622.024504</td>\n",
       "      <td>820.705714</td>\n",
       "      <td>975.002096</td>\n",
       "      <td>1108.032300</td>\n",
       "      <td>1228.148143</td>\n",
       "      <td>1339.437507</td>\n",
       "      <td>1444.243512</td>\n",
       "      <td>1544.706350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276.583390</td>\n",
       "      <td>372.852857</td>\n",
       "      <td>479.016150</td>\n",
       "      <td>557.218753</td>\n",
       "      <td>622.024504</td>\n",
       "      <td>820.705714</td>\n",
       "      <td>975.002096</td>\n",
       "      <td>1108.032300</td>\n",
       "      <td>1228.148143</td>\n",
       "      <td>1339.437507</td>\n",
       "      <td>1444.243512</td>\n",
       "      <td>1544.706350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276.583390</td>\n",
       "      <td>372.852857</td>\n",
       "      <td>479.016150</td>\n",
       "      <td>557.218753</td>\n",
       "      <td>622.024504</td>\n",
       "      <td>820.705714</td>\n",
       "      <td>975.002096</td>\n",
       "      <td>1108.032300</td>\n",
       "      <td>1228.148143</td>\n",
       "      <td>1339.437507</td>\n",
       "      <td>1444.243512</td>\n",
       "      <td>1544.706350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19395</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945996</td>\n",
       "      <td>1029.945996</td>\n",
       "      <td>1129.945996</td>\n",
       "      <td>1229.945996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19396</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945996</td>\n",
       "      <td>1029.945996</td>\n",
       "      <td>1129.945996</td>\n",
       "      <td>1229.945996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19397</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945996</td>\n",
       "      <td>1029.945996</td>\n",
       "      <td>1129.945996</td>\n",
       "      <td>1229.945996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19398</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945996</td>\n",
       "      <td>1029.945996</td>\n",
       "      <td>1129.945996</td>\n",
       "      <td>1229.945996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19399</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945996</td>\n",
       "      <td>1029.945996</td>\n",
       "      <td>1129.945996</td>\n",
       "      <td>1229.945996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19400 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          E_c(10)     E_c(25)     E_c(50)     E_c(75)    E_c(100)    E_c(200)  \\\n",
       "0      276.583390  372.852857  479.016150  557.218753  622.024504  820.705714   \n",
       "1      276.583390  372.852857  479.016150  557.218753  622.024504  820.705714   \n",
       "2      276.583390  372.852857  479.016150  557.218753  622.024504  820.705714   \n",
       "3      276.583390  372.852857  479.016150  557.218753  622.024504  820.705714   \n",
       "4      276.583390  372.852857  479.016150  557.218753  622.024504  820.705714   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "19395  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "19396  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "19397  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "19398  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "19399  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "\n",
       "         E_c(300)     E_c(400)     E_c(500)     E_c(600)     E_c(700)  \\\n",
       "0      975.002096  1108.032300  1228.148143  1339.437507  1444.243512   \n",
       "1      975.002096  1108.032300  1228.148143  1339.437507  1444.243512   \n",
       "2      975.002096  1108.032300  1228.148143  1339.437507  1444.243512   \n",
       "3      975.002096  1108.032300  1228.148143  1339.437507  1444.243512   \n",
       "4      975.002096  1108.032300  1228.148143  1339.437507  1444.243512   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "19395  722.015264   829.584262   929.945996  1029.945996  1129.945996   \n",
       "19396  722.015264   829.584262   929.945996  1029.945996  1129.945996   \n",
       "19397  722.015264   829.584262   929.945996  1029.945996  1129.945996   \n",
       "19398  722.015264   829.584262   929.945996  1029.945996  1129.945996   \n",
       "19399  722.015264   829.584262   929.945996  1029.945996  1129.945996   \n",
       "\n",
       "          E_c(800)  \n",
       "0      1544.706350  \n",
       "1      1544.706350  \n",
       "2      1544.706350  \n",
       "3      1544.706350  \n",
       "4      1544.706350  \n",
       "...            ...  \n",
       "19395  1229.945996  \n",
       "19396  1229.945996  \n",
       "19397  1229.945996  \n",
       "19398  1229.945996  \n",
       "19399  1229.945996  \n",
       "\n",
       "[19400 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED LOG ERROR (MSLE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[0.00741371 0.0052676  0.00413353 0.00378284 0.004206   0.00224487\n",
      " 0.00153855 0.00167105 0.00256079 0.00387248 0.00532806 0.00678231]\n",
      "Uniform average\n",
      "0.004066813834186747\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED ERROR (MSE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[ 1115.66087519  1422.4479675   1504.35676754  1821.53368675\n",
      "  2427.55141189  2234.85478701  2014.54092683  2789.96074376\n",
      "  5620.99492951 10973.66794876 19149.79950001 30354.85806938]\n",
      "Uniform average\n",
      "6785.852301178563\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Prediction metrics (using the actual test dataset)\n",
      "===================================================================================================================\n",
      ">> PREDICTIONS AND REAL VALUES:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step\n",
      "Predictions of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 209.35394,  279.14328,  363.41046, ..., 1016.5093 , 1116.0603 ,\n",
       "        1214.6599 ],\n",
       "       [ 209.94879,  276.20502,  354.78824, ...,  992.38416, 1092.5032 ,\n",
       "        1191.6245 ],\n",
       "       [ 209.4826 ,  281.2745 ,  368.51736, ..., 1029.7454 , 1129.0332 ,\n",
       "        1227.4086 ],\n",
       "       ...,\n",
       "       [ 274.8626 ,  384.13568,  490.90396, ..., 1301.4802 , 1416.7961 ,\n",
       "        1527.7471 ],\n",
       "       [ 280.38184,  397.27625,  512.0648 , ..., 1252.406  , 1354.4628 ,\n",
       "        1455.4402 ],\n",
       "       [ 273.82553,  389.47516,  503.46747, ..., 1257.8024 , 1361.4539 ,\n",
       "        1461.2849 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_c(10)</th>\n",
       "      <th>E_c(25)</th>\n",
       "      <th>E_c(50)</th>\n",
       "      <th>E_c(75)</th>\n",
       "      <th>E_c(100)</th>\n",
       "      <th>E_c(200)</th>\n",
       "      <th>E_c(300)</th>\n",
       "      <th>E_c(400)</th>\n",
       "      <th>E_c(500)</th>\n",
       "      <th>E_c(600)</th>\n",
       "      <th>E_c(700)</th>\n",
       "      <th>E_c(800)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24200</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945992</td>\n",
       "      <td>1029.945992</td>\n",
       "      <td>1129.945992</td>\n",
       "      <td>1229.945992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24201</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945992</td>\n",
       "      <td>1029.945992</td>\n",
       "      <td>1129.945992</td>\n",
       "      <td>1229.945992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24202</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945992</td>\n",
       "      <td>1029.945992</td>\n",
       "      <td>1129.945992</td>\n",
       "      <td>1229.945992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24203</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945992</td>\n",
       "      <td>1029.945992</td>\n",
       "      <td>1129.945992</td>\n",
       "      <td>1229.945992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24204</th>\n",
       "      <td>229.674954</td>\n",
       "      <td>299.164609</td>\n",
       "      <td>362.525289</td>\n",
       "      <td>407.755484</td>\n",
       "      <td>446.613232</td>\n",
       "      <td>599.701360</td>\n",
       "      <td>722.015264</td>\n",
       "      <td>829.584262</td>\n",
       "      <td>929.945992</td>\n",
       "      <td>1029.945992</td>\n",
       "      <td>1129.945992</td>\n",
       "      <td>1229.945992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30295</th>\n",
       "      <td>284.859202</td>\n",
       "      <td>439.667175</td>\n",
       "      <td>529.611941</td>\n",
       "      <td>592.667261</td>\n",
       "      <td>643.331503</td>\n",
       "      <td>811.114901</td>\n",
       "      <td>964.023356</td>\n",
       "      <td>1095.948633</td>\n",
       "      <td>1215.131408</td>\n",
       "      <td>1325.605161</td>\n",
       "      <td>1429.681834</td>\n",
       "      <td>1529.890602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30296</th>\n",
       "      <td>284.859202</td>\n",
       "      <td>439.667175</td>\n",
       "      <td>529.611941</td>\n",
       "      <td>592.667261</td>\n",
       "      <td>643.331503</td>\n",
       "      <td>811.114901</td>\n",
       "      <td>964.023356</td>\n",
       "      <td>1095.948633</td>\n",
       "      <td>1215.131408</td>\n",
       "      <td>1325.605161</td>\n",
       "      <td>1429.681834</td>\n",
       "      <td>1529.890602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30297</th>\n",
       "      <td>284.859202</td>\n",
       "      <td>439.667175</td>\n",
       "      <td>529.611941</td>\n",
       "      <td>592.667261</td>\n",
       "      <td>643.331503</td>\n",
       "      <td>811.114901</td>\n",
       "      <td>964.023356</td>\n",
       "      <td>1095.948633</td>\n",
       "      <td>1215.131408</td>\n",
       "      <td>1325.605161</td>\n",
       "      <td>1429.681834</td>\n",
       "      <td>1529.890602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30298</th>\n",
       "      <td>284.859202</td>\n",
       "      <td>439.667175</td>\n",
       "      <td>529.611941</td>\n",
       "      <td>592.667261</td>\n",
       "      <td>643.331503</td>\n",
       "      <td>811.114901</td>\n",
       "      <td>964.023356</td>\n",
       "      <td>1095.948633</td>\n",
       "      <td>1215.131408</td>\n",
       "      <td>1325.605161</td>\n",
       "      <td>1429.681834</td>\n",
       "      <td>1529.890602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30299</th>\n",
       "      <td>284.859202</td>\n",
       "      <td>439.667175</td>\n",
       "      <td>529.611941</td>\n",
       "      <td>592.667261</td>\n",
       "      <td>643.331503</td>\n",
       "      <td>811.114901</td>\n",
       "      <td>964.023356</td>\n",
       "      <td>1095.948633</td>\n",
       "      <td>1215.131408</td>\n",
       "      <td>1325.605161</td>\n",
       "      <td>1429.681834</td>\n",
       "      <td>1529.890602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6100 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          E_c(10)     E_c(25)     E_c(50)     E_c(75)    E_c(100)    E_c(200)  \\\n",
       "24200  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "24201  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "24202  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "24203  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "24204  229.674954  299.164609  362.525289  407.755484  446.613232  599.701360   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "30295  284.859202  439.667175  529.611941  592.667261  643.331503  811.114901   \n",
       "30296  284.859202  439.667175  529.611941  592.667261  643.331503  811.114901   \n",
       "30297  284.859202  439.667175  529.611941  592.667261  643.331503  811.114901   \n",
       "30298  284.859202  439.667175  529.611941  592.667261  643.331503  811.114901   \n",
       "30299  284.859202  439.667175  529.611941  592.667261  643.331503  811.114901   \n",
       "\n",
       "         E_c(300)     E_c(400)     E_c(500)     E_c(600)     E_c(700)  \\\n",
       "24200  722.015264   829.584262   929.945992  1029.945992  1129.945992   \n",
       "24201  722.015264   829.584262   929.945992  1029.945992  1129.945992   \n",
       "24202  722.015264   829.584262   929.945992  1029.945992  1129.945992   \n",
       "24203  722.015264   829.584262   929.945992  1029.945992  1129.945992   \n",
       "24204  722.015264   829.584262   929.945992  1029.945992  1129.945992   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "30295  964.023356  1095.948633  1215.131408  1325.605161  1429.681834   \n",
       "30296  964.023356  1095.948633  1215.131408  1325.605161  1429.681834   \n",
       "30297  964.023356  1095.948633  1215.131408  1325.605161  1429.681834   \n",
       "30298  964.023356  1095.948633  1215.131408  1325.605161  1429.681834   \n",
       "30299  964.023356  1095.948633  1215.131408  1325.605161  1429.681834   \n",
       "\n",
       "          E_c(800)  \n",
       "24200  1229.945992  \n",
       "24201  1229.945992  \n",
       "24202  1229.945992  \n",
       "24203  1229.945992  \n",
       "24204  1229.945992  \n",
       "...            ...  \n",
       "30295  1529.890602  \n",
       "30296  1529.890602  \n",
       "30297  1529.890602  \n",
       "30298  1529.890602  \n",
       "30299  1529.890602  \n",
       "\n",
       "[6100 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED LOG ERROR (MSLE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[0.00623982 0.00559544 0.00548615 0.00533075 0.00622303 0.00285674\n",
      " 0.00261312 0.00329583 0.00460767 0.00686023 0.00934943 0.01176713]\n",
      "Uniform average\n",
      "0.005852112310583705\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED ERROR (MSE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[  965.22454287  1600.3606767   1584.72202566  1958.61953554\n",
      "  2985.62186085  2514.89764298  2971.25239811  4911.06296306\n",
      "  8482.36549199 14809.38309811 24052.23845283 36295.01694435]\n",
      "Uniform average\n",
      "8594.230469420974\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Learning curve\n",
      "===================================================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Saving the ANN model info:\n",
      "===================================================================================================================\n",
      "The ANNs model info have been saved in the \"linNS_dnn3_enrg_32X_rwsh.pkl\" file !!!\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Building a regression ANN model\n",
    "regression_ANN(\"linNS_reg_data_pp8mr16s100_rwshuffled.csv\",mag_reg=\"enrg\",test_ratio=0.2,val_ratio=0.2,samples_per_EOS=100).train_model(\"no\",neurons_enrg_32X,actvs_enrg_32X,drops_enrg_32X,adam_learn_rate=1e-3,train_epochs=1000,batch_size=128,filesave=\"linNS_dnn3_enrg_32X_rwsh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3713fd2",
   "metadata": {},
   "source": [
    "# 2. Quark Stars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9037cc5d",
   "metadata": {},
   "source": [
    "## **2.1 Using 8 M-R points**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15edc719",
   "metadata": {},
   "source": [
    "### B. Predicting Energy on center $E_c$ Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42d447e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists for the neurons, activation functions and dropouts in the layers of the network\n",
    "neurons_enrg_16X = [128,64,32]\n",
    "actvs_enrg_16X = [\"relu\",\"relu\",\"relu\"]\n",
    "drops_enrg_16X = [0.50,0.50,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe99d97",
   "metadata": {},
   "source": [
    "#### ->Using rowwise-shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6aca364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the datasets\n",
    "# regression_ANN(filename=\"QS_reg_data_pp8mr8s100_rwshuffled.csv\",mag_reg=\"enrg\",test_ratio=0.2,val_ratio=0.2,samples_per_EOS=100).show_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f923fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AND ASSESSING AN ARTIFICIAL NEURAL NETWORK REGRESSION MODEL\n",
      "\n",
      "\n",
      ">Preliminaries\n",
      "===================================================================================================================\n",
      ">> DATA INFO AND SCALING:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Y (response) data type: \"enrg\"\n",
      "Number of Y columns:  12\n",
      "X (explanatory) data type: \"Mass\" and \"Radius\"\n",
      "Number of X columns:  16\n",
      "The scaling of the X (explanatory) data has been completed\n",
      "The scaling of the Y (response) data has been completed\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Compiling and fitting the model\n",
      "===================================================================================================================\n",
      ">> COMPILATION SUMMARY:\n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m396\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,804</span> (53.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,804\u001b[0m (53.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,356</span> (52.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,356\u001b[0m (52.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> TRAINING:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Ongoing fitting process...\n",
      "Epoch 1/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 44.8378 - val_loss: 26.1044\n",
      "Epoch 2/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 24.8946 - val_loss: 18.7127\n",
      "Epoch 3/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 17.6031 - val_loss: 14.3527\n",
      "Epoch 4/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13.6243 - val_loss: 11.9146\n",
      "Epoch 5/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 11.1224 - val_loss: 9.6234\n",
      "Epoch 6/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 9.2956 - val_loss: 8.0847\n",
      "Epoch 7/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7.9329 - val_loss: 6.9769\n",
      "Epoch 8/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6.7558 - val_loss: 5.8857\n",
      "Epoch 9/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.8397 - val_loss: 5.1116\n",
      "Epoch 10/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.0581 - val_loss: 4.4318\n",
      "Epoch 11/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4.4029 - val_loss: 3.8619\n",
      "Epoch 12/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3.6957 - val_loss: 3.2552\n",
      "Epoch 13/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3.1281 - val_loss: 2.7989\n",
      "Epoch 14/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.6735 - val_loss: 2.4036\n",
      "Epoch 15/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.2868 - val_loss: 2.0548\n",
      "Epoch 16/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.9583 - val_loss: 1.7566\n",
      "Epoch 17/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6646 - val_loss: 1.4958\n",
      "Epoch 18/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.4145 - val_loss: 1.2692\n",
      "Epoch 19/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.2000 - val_loss: 1.0766\n",
      "Epoch 20/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.0039 - val_loss: 0.9018\n",
      "Epoch 21/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8418 - val_loss: 0.7483\n",
      "Epoch 22/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.7051 - val_loss: 0.6259\n",
      "Epoch 23/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5859 - val_loss: 0.5120\n",
      "Epoch 24/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4841 - val_loss: 0.4209\n",
      "Epoch 25/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3896 - val_loss: 0.3466\n",
      "Epoch 26/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3174 - val_loss: 0.2754\n",
      "Epoch 27/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2553 - val_loss: 0.2222\n",
      "Epoch 28/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2042 - val_loss: 0.1762\n",
      "Epoch 29/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1622 - val_loss: 0.1396\n",
      "Epoch 30/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1264 - val_loss: 0.1083\n",
      "Epoch 31/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0988 - val_loss: 0.0823\n",
      "Epoch 32/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0777 - val_loss: 0.0629\n",
      "Epoch 33/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0584 - val_loss: 0.0489\n",
      "Epoch 34/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0449 - val_loss: 0.0358\n",
      "Epoch 35/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0345 - val_loss: 0.0261\n",
      "Epoch 36/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0257 - val_loss: 0.0198\n",
      "Epoch 37/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0197 - val_loss: 0.0144\n",
      "Epoch 38/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0161 - val_loss: 0.0109\n",
      "Epoch 39/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0122 - val_loss: 0.0085\n",
      "Epoch 40/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0099 - val_loss: 0.0068\n",
      "Epoch 41/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0099 - val_loss: 0.0058\n",
      "Epoch 42/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 43/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 44/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0071 - val_loss: 0.0037\n",
      "Epoch 45/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 46/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 47/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 48/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 49/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 50/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 51/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 52/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 53/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 54/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 55/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 56/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0052 - val_loss: 0.0026\n",
      "Epoch 57/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 58/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0061 - val_loss: 0.0027\n",
      "Epoch 59/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 60/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 61/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 62/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 63/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 64/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 65/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 66/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 67/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 68/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 69/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 70/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 71/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 72/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 73/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 74/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 75/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 76/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 77/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 78/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 79/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 80/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 81/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 82/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 83/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 84/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 85/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 86/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 87/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 88/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 89/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 90/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 91/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 92/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 93/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 94/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 95/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 96/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 97/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 98/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 99/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 100/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 101/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 102/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 103/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 104/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 105/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 106/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 107/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 108/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 109/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 110/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 111/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 112/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 113/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 114/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 115/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 116/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 117/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 118/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 119/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 120/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 121/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 122/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 123/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 124/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 125/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 126/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 127/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 128/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 129/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 130/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 131/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 132/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 133/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 134/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 135/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 136/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 137/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 138/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 139/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 140/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 141/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 142/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 143/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 144/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 145/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 146/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 147/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 148/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 149/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 150/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 151/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 152/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 153/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 154/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 155/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 156/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 157/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 158/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 159/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 160/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 161/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 162/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 163/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 164/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 165/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 166/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 167/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 168/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 169/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 170/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 171/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 172/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 173/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 174/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 175/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 176/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 177/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 178/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 179/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 180/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 181/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 182/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 183/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 184/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 185/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 186/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 187/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 188/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 189/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 190/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 191/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 192/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 193/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 194/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 195/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 196/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 197/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 198/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 199/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 200/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 201/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 202/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 203/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 204/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 205/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 206/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 207/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 208/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 209/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 210/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 211/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 212/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 213/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 214/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 215/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 216/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 217/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 218/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 219/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 220/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 221/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 222/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 223/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 224/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 225/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 226/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 227/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 228/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 229/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 230/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 231/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 232/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 233/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 234/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 235/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 236/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 237/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 238/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 239/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 240/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 241/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 242/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 243/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 244/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 245/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 246/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 247/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 248/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 249/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 250/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 251/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 252/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 253/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 254/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 255/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 256/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 257/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 258/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 259/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 260/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 261/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 262/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 263/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 264/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 265/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 266/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 267/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 268/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 269/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 270/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 271/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 272/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 273/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 274/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 275/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 276/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 277/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 278/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 279/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 280/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 281/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 282/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 283/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 284/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 285/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 286/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 287/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 288/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 289/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 290/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 291/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 292/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 293/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 294/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 295/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 296/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 297/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 298/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 299/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 300/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 301/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 302/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 303/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 304/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 305/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 306/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 307/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 308/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 309/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 310/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 311/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 312/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 313/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 314/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 315/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 316/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 317/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 318/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 319/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 320/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 321/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 322/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 323/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 324/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 325/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 326/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 327/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 328/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 329/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 330/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 331/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 332/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 333/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 334/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 335/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 336/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 337/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 338/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 339/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 340/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 341/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 342/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 343/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 344/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 345/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 346/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 347/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 348/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 349/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 350/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 351/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 352/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 353/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 354/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 355/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 356/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 357/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 358/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 359/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 360/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 361/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 362/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 363/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 364/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 365/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 366/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 367/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 368/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 369/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 370/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 371/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 372/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 373/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 374/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 375/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 376/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 377/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 378/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 379/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 380/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 381/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 382/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 383/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 384/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 385/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 386/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 387/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 388/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 389/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 390/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 391/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 392/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 393/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 394/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 395/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 396/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 397/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 398/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 399/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 400/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 401/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 402/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 403/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 404/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 405/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 406/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 407/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 408/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 409/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 410/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 411/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 412/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 413/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 414/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 415/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 416/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 417/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 418/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 419/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 420/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 421/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 422/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 423/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 424/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 425/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 426/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 427/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 428/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 429/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 430/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 431/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 432/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 433/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 434/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 435/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 436/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 437/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 438/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 439/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 440/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 441/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 442/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 443/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 444/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 445/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 446/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 447/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 448/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 449/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 450/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 451/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 452/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 453/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 454/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 455/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 456/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 457/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 458/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 459/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 460/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 461/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 462/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 463/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 464/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 465/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 466/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 467/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 468/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 469/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 470/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 471/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 472/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 473/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 474/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 475/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 476/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 477/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 478/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 479/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 480/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 481/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 482/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 483/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 484/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 485/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 486/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 487/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 488/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 489/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 490/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 491/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 492/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 493/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 494/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 495/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 496/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 497/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 498/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 499/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 500/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 501/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 502/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 503/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 504/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 505/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 506/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 507/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 508/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 509/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 510/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 511/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 512/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 513/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 514/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 515/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 516/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 517/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 518/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 519/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 520/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 521/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 522/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 523/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 524/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 525/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 526/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 527/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 528/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 529/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 530/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 531/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 532/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 533/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 534/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 535/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 536/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 537/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 538/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 539/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 540/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 541/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 542/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 543/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 544/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 545/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 546/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 547/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 548/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 549/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 550/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 551/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 552/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 553/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 554/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 555/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 556/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 557/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 558/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 559/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 560/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 561/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 562/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 563/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 564/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 565/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 566/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 567/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 568/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 569/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 570/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 571/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 572/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 573/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 574/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 575/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 576/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 577/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 578/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 579/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 580/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 581/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 582/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 583/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 584/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 585/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 586/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 587/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 588/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 589/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 590/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 591/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 592/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 593/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 594/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 595/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 596/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 597/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 598/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 599/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 600/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 601/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 602/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 603/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 604/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 605/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 606/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 607/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 608/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 609/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 610/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 611/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 612/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 613/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 614/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 615/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 616/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 617/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 618/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 619/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 620/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 621/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 622/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 623/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 624/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 625/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 626/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 627/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 628/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 629/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 630/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 631/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 632/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 633/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 634/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 635/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 636/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 637/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 638/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 639/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 640/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 641/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 642/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 643/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 644/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 645/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 646/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 647/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 648/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 649/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 650/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 651/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 652/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 653/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 654/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 655/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 656/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 657/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 658/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 659/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 660/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 661/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 662/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 663/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 664/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 665/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 666/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 667/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 668/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 669/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 670/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 671/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 672/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 673/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 674/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 675/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 676/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 677/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 678/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 679/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 680/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 681/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 682/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 683/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 684/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 685/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 686/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 687/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 688/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 689/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 690/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 691/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 692/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 693/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 694/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 695/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 696/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 697/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 698/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 699/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 700/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 701/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 702/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 703/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 704/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 705/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 706/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 707/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 708/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 709/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 710/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 711/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 712/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 713/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 714/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 715/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 716/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 717/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 718/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 719/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 720/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 721/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 722/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 723/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 724/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 725/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 726/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 727/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 728/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 729/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 730/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 731/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 732/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 733/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 734/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 735/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 736/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 737/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 738/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 739/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 740/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 741/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 742/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 743/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 744/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 745/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 746/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 747/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 748/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 749/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 750/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 751/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 752/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 753/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 754/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 755/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 756/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 757/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 758/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 759/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 760/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 761/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 762/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 763/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 764/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 765/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 766/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 767/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 768/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 769/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 770/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 771/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 772/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 773/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 774/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 775/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 776/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 777/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 778/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 779/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 780/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 781/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 782/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 783/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 784/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 785/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 786/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 787/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 788/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 789/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 790/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 791/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 792/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 793/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 794/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 795/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 796/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 797/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 798/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 799/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 800/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 801/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 802/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 803/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 804/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 805/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 806/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 807/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 808/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 809/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 810/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 811/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 812/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 813/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 814/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 815/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 816/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 817/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 818/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 819/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 820/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 821/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 822/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 823/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 824/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 825/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 826/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 827/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 828/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 829/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 830/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 831/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 832/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 833/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 834/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 835/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 836/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 837/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 838/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 839/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 840/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 841/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 842/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 843/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 844/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 845/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 846/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 847/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 848/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 849/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 850/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 851/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 852/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 853/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 854/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 855/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 856/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 857/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 858/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 859/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 860/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 861/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 862/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 863/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 864/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 865/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 866/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 867/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 868/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 869/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 870/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 871/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 872/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 873/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 874/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 875/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 876/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 877/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 878/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 879/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 880/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 881/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 882/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 883/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 884/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 885/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 886/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 887/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 888/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 889/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 890/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 891/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 892/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 893/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 894/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 895/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 896/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 897/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 898/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 899/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 900/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 901/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 902/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 903/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 904/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 905/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 906/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 907/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 908/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 909/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 910/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 911/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 912/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 913/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 914/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 915/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 916/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 917/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 918/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 919/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 920/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 921/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 922/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 923/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 924/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 925/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 926/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 927/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 928/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 929/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 930/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 931/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 932/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 933/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 934/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 935/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 936/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 937/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 938/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 939/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 940/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 941/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 942/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 943/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 944/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 945/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 946/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 947/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 948/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 949/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 950/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 951/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 952/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 953/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 954/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 955/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 956/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 957/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 958/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 959/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 960/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 961/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 962/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 963/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 964/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 965/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 966/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 967/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 968/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 969/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 970/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 971/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 972/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 973/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 974/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 975/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 976/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 977/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 978/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 979/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 980/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 981/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 982/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 983/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 984/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 985/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 986/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 987/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 988/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 989/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 990/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 991/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 992/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 993/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 994/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 995/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 996/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 997/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 998/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 999/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 1000/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "The fitting process has been completed\n",
      "Elapsed fitting time: 11.0'45.00\"\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Overfitting metrics (using the train dataset as test dataset)\n",
      "===================================================================================================================\n",
      ">> PREDICTIONS AND REAL VALUES:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m1782/1782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step\n",
      "Predictions of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 523.53485,  767.4679 , 1041.4731 , ..., 3011.3787 , 3296.5967 ,\n",
       "        3582.4436 ],\n",
       "       [ 535.0094 ,  748.6827 ,  992.1356 , ..., 2800.345  , 3066.9668 ,\n",
       "        3334.963  ],\n",
       "       [ 495.57886,  759.9786 , 1053.3625 , ..., 3117.2192 , 3412.8904 ,\n",
       "        3708.6353 ],\n",
       "       ...,\n",
       "       [ 227.78674,  395.3899 ,  600.26514, ..., 2241.7812 , 2490.9639 ,\n",
       "        2742.323  ],\n",
       "       [ 214.99088,  379.51602,  581.76917, ..., 2211.4045 , 2459.2905 ,\n",
       "        2709.4084 ],\n",
       "       [ 217.60852,  372.37183,  564.63055, ..., 2140.2397 , 2381.8315 ,\n",
       "        2625.8723 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_c(10)</th>\n",
       "      <th>E_c(100)</th>\n",
       "      <th>E_c(200)</th>\n",
       "      <th>E_c(300)</th>\n",
       "      <th>E_c(400)</th>\n",
       "      <th>E_c(500)</th>\n",
       "      <th>E_c(600)</th>\n",
       "      <th>E_c(700)</th>\n",
       "      <th>E_c(800)</th>\n",
       "      <th>E_c(900)</th>\n",
       "      <th>E_c(1000)</th>\n",
       "      <th>E_c(1100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>498.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1368.000000</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>2568.00000</td>\n",
       "      <td>2868.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3468.000000</td>\n",
       "      <td>3768.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>498.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1368.000000</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>2568.00000</td>\n",
       "      <td>2868.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3468.000000</td>\n",
       "      <td>3768.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>498.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1368.000000</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>2568.00000</td>\n",
       "      <td>2868.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3468.000000</td>\n",
       "      <td>3768.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>498.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1368.000000</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>2568.00000</td>\n",
       "      <td>2868.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3468.000000</td>\n",
       "      <td>3768.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>498.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1368.000000</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>2568.00000</td>\n",
       "      <td>2868.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3468.000000</td>\n",
       "      <td>3768.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56995</th>\n",
       "      <td>215.446869</td>\n",
       "      <td>374.558577</td>\n",
       "      <td>571.504921</td>\n",
       "      <td>781.695495</td>\n",
       "      <td>1001.046783</td>\n",
       "      <td>1227.222158</td>\n",
       "      <td>1458.736193</td>\n",
       "      <td>1694.57501</td>\n",
       "      <td>1934.010026</td>\n",
       "      <td>2176.496809</td>\n",
       "      <td>2421.615832</td>\n",
       "      <td>2669.0357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56996</th>\n",
       "      <td>215.446869</td>\n",
       "      <td>374.558577</td>\n",
       "      <td>571.504921</td>\n",
       "      <td>781.695495</td>\n",
       "      <td>1001.046783</td>\n",
       "      <td>1227.222158</td>\n",
       "      <td>1458.736193</td>\n",
       "      <td>1694.57501</td>\n",
       "      <td>1934.010026</td>\n",
       "      <td>2176.496809</td>\n",
       "      <td>2421.615832</td>\n",
       "      <td>2669.0357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56997</th>\n",
       "      <td>215.446869</td>\n",
       "      <td>374.558577</td>\n",
       "      <td>571.504921</td>\n",
       "      <td>781.695495</td>\n",
       "      <td>1001.046783</td>\n",
       "      <td>1227.222158</td>\n",
       "      <td>1458.736193</td>\n",
       "      <td>1694.57501</td>\n",
       "      <td>1934.010026</td>\n",
       "      <td>2176.496809</td>\n",
       "      <td>2421.615832</td>\n",
       "      <td>2669.0357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56998</th>\n",
       "      <td>215.446869</td>\n",
       "      <td>374.558577</td>\n",
       "      <td>571.504921</td>\n",
       "      <td>781.695495</td>\n",
       "      <td>1001.046783</td>\n",
       "      <td>1227.222158</td>\n",
       "      <td>1458.736193</td>\n",
       "      <td>1694.57501</td>\n",
       "      <td>1934.010026</td>\n",
       "      <td>2176.496809</td>\n",
       "      <td>2421.615832</td>\n",
       "      <td>2669.0357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56999</th>\n",
       "      <td>215.446869</td>\n",
       "      <td>374.558577</td>\n",
       "      <td>571.504921</td>\n",
       "      <td>781.695495</td>\n",
       "      <td>1001.046783</td>\n",
       "      <td>1227.222158</td>\n",
       "      <td>1458.736193</td>\n",
       "      <td>1694.57501</td>\n",
       "      <td>1934.010026</td>\n",
       "      <td>2176.496809</td>\n",
       "      <td>2421.615832</td>\n",
       "      <td>2669.0357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          E_c(10)    E_c(100)     E_c(200)     E_c(300)     E_c(400)  \\\n",
       "0      498.000000  768.000000  1068.000000  1368.000000  1668.000000   \n",
       "1      498.000000  768.000000  1068.000000  1368.000000  1668.000000   \n",
       "2      498.000000  768.000000  1068.000000  1368.000000  1668.000000   \n",
       "3      498.000000  768.000000  1068.000000  1368.000000  1668.000000   \n",
       "4      498.000000  768.000000  1068.000000  1368.000000  1668.000000   \n",
       "...           ...         ...          ...          ...          ...   \n",
       "56995  215.446869  374.558577   571.504921   781.695495  1001.046783   \n",
       "56996  215.446869  374.558577   571.504921   781.695495  1001.046783   \n",
       "56997  215.446869  374.558577   571.504921   781.695495  1001.046783   \n",
       "56998  215.446869  374.558577   571.504921   781.695495  1001.046783   \n",
       "56999  215.446869  374.558577   571.504921   781.695495  1001.046783   \n",
       "\n",
       "          E_c(500)     E_c(600)    E_c(700)     E_c(800)     E_c(900)  \\\n",
       "0      1968.000000  2268.000000  2568.00000  2868.000000  3168.000000   \n",
       "1      1968.000000  2268.000000  2568.00000  2868.000000  3168.000000   \n",
       "2      1968.000000  2268.000000  2568.00000  2868.000000  3168.000000   \n",
       "3      1968.000000  2268.000000  2568.00000  2868.000000  3168.000000   \n",
       "4      1968.000000  2268.000000  2568.00000  2868.000000  3168.000000   \n",
       "...            ...          ...         ...          ...          ...   \n",
       "56995  1227.222158  1458.736193  1694.57501  1934.010026  2176.496809   \n",
       "56996  1227.222158  1458.736193  1694.57501  1934.010026  2176.496809   \n",
       "56997  1227.222158  1458.736193  1694.57501  1934.010026  2176.496809   \n",
       "56998  1227.222158  1458.736193  1694.57501  1934.010026  2176.496809   \n",
       "56999  1227.222158  1458.736193  1694.57501  1934.010026  2176.496809   \n",
       "\n",
       "         E_c(1000)  E_c(1100)  \n",
       "0      3468.000000  3768.0000  \n",
       "1      3468.000000  3768.0000  \n",
       "2      3468.000000  3768.0000  \n",
       "3      3468.000000  3768.0000  \n",
       "4      3468.000000  3768.0000  \n",
       "...            ...        ...  \n",
       "56995  2421.615832  2669.0357  \n",
       "56996  2421.615832  2669.0357  \n",
       "56997  2421.615832  2669.0357  \n",
       "56998  2421.615832  2669.0357  \n",
       "56999  2421.615832  2669.0357  \n",
       "\n",
       "[57000 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED LOG ERROR (MSLE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[0.00622852 0.00258508 0.00246568 0.00268339 0.00283778 0.00291271\n",
      " 0.00292927 0.0029083  0.00286405 0.00280556 0.00273918 0.00266966]\n",
      "Uniform average\n",
      "0.0030524306791893147\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED ERROR (MSE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[ 2487.93637429  2454.50143054  3321.82593836  4867.55461092\n",
      "  6918.13380548  9380.49020528 12178.62164987 15257.90902889\n",
      " 18572.58666705 22098.80705512 25801.34728154 29671.83914342]\n",
      "Uniform average\n",
      "12750.962765896651\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Prediction metrics (using the actual test dataset)\n",
      "===================================================================================================================\n",
      ">> PREDICTIONS AND REAL VALUES:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step\n",
      "Predictions of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 806.27716, 1069.3391 , 1361.7917 , ..., 3426.5564 , 3722.4941 ,\n",
       "        4019.4192 ],\n",
       "       [ 774.1094 , 1036.5648 , 1328.664  , ..., 3390.949  , 3686.6926 ,\n",
       "        3983.3657 ],\n",
       "       [ 780.4017 , 1043.5714 , 1336.3009 , ..., 3402.4497 , 3698.4602 ,\n",
       "        3995.4136 ],\n",
       "       ...,\n",
       "       [ 458.57733,  651.5092 ,  875.84296, ..., 2588.3967 , 2844.8066 ,\n",
       "        3103.345  ],\n",
       "       [ 443.96616,  634.13214,  855.6523 , ..., 2554.6655 , 2809.5522 ,\n",
       "        3066.6118 ],\n",
       "       [ 456.44537,  648.99994,  873.123  , ..., 2584.861  , 2841.2332 ,\n",
       "        3099.7578 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_c(10)</th>\n",
       "      <th>E_c(100)</th>\n",
       "      <th>E_c(200)</th>\n",
       "      <th>E_c(300)</th>\n",
       "      <th>E_c(400)</th>\n",
       "      <th>E_c(500)</th>\n",
       "      <th>E_c(600)</th>\n",
       "      <th>E_c(700)</th>\n",
       "      <th>E_c(800)</th>\n",
       "      <th>E_c(900)</th>\n",
       "      <th>E_c(1000)</th>\n",
       "      <th>E_c(1100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71300</th>\n",
       "      <td>852.000000</td>\n",
       "      <td>1122.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1722.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2322.000000</td>\n",
       "      <td>2622.00000</td>\n",
       "      <td>2922.000000</td>\n",
       "      <td>3222.000000</td>\n",
       "      <td>3522.000000</td>\n",
       "      <td>3822.000000</td>\n",
       "      <td>4122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71301</th>\n",
       "      <td>852.000000</td>\n",
       "      <td>1122.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1722.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2322.000000</td>\n",
       "      <td>2622.00000</td>\n",
       "      <td>2922.000000</td>\n",
       "      <td>3222.000000</td>\n",
       "      <td>3522.000000</td>\n",
       "      <td>3822.000000</td>\n",
       "      <td>4122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71302</th>\n",
       "      <td>852.000000</td>\n",
       "      <td>1122.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1722.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2322.000000</td>\n",
       "      <td>2622.00000</td>\n",
       "      <td>2922.000000</td>\n",
       "      <td>3222.000000</td>\n",
       "      <td>3522.000000</td>\n",
       "      <td>3822.000000</td>\n",
       "      <td>4122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71303</th>\n",
       "      <td>852.000000</td>\n",
       "      <td>1122.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1722.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2322.000000</td>\n",
       "      <td>2622.00000</td>\n",
       "      <td>2922.000000</td>\n",
       "      <td>3222.000000</td>\n",
       "      <td>3522.000000</td>\n",
       "      <td>3822.000000</td>\n",
       "      <td>4122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71304</th>\n",
       "      <td>852.000000</td>\n",
       "      <td>1122.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1722.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2322.000000</td>\n",
       "      <td>2622.00000</td>\n",
       "      <td>2922.000000</td>\n",
       "      <td>3222.000000</td>\n",
       "      <td>3522.000000</td>\n",
       "      <td>3822.000000</td>\n",
       "      <td>4122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89095</th>\n",
       "      <td>471.758594</td>\n",
       "      <td>637.295412</td>\n",
       "      <td>834.061872</td>\n",
       "      <td>1040.614857</td>\n",
       "      <td>1254.607242</td>\n",
       "      <td>1474.502678</td>\n",
       "      <td>1699.23047</td>\n",
       "      <td>1928.009096</td>\n",
       "      <td>2160.247412</td>\n",
       "      <td>2395.485434</td>\n",
       "      <td>2633.356884</td>\n",
       "      <td>2873.564462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89096</th>\n",
       "      <td>471.758594</td>\n",
       "      <td>637.295412</td>\n",
       "      <td>834.061872</td>\n",
       "      <td>1040.614857</td>\n",
       "      <td>1254.607242</td>\n",
       "      <td>1474.502678</td>\n",
       "      <td>1699.23047</td>\n",
       "      <td>1928.009096</td>\n",
       "      <td>2160.247412</td>\n",
       "      <td>2395.485434</td>\n",
       "      <td>2633.356884</td>\n",
       "      <td>2873.564462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89097</th>\n",
       "      <td>471.758594</td>\n",
       "      <td>637.295412</td>\n",
       "      <td>834.061872</td>\n",
       "      <td>1040.614857</td>\n",
       "      <td>1254.607242</td>\n",
       "      <td>1474.502678</td>\n",
       "      <td>1699.23047</td>\n",
       "      <td>1928.009096</td>\n",
       "      <td>2160.247412</td>\n",
       "      <td>2395.485434</td>\n",
       "      <td>2633.356884</td>\n",
       "      <td>2873.564462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89098</th>\n",
       "      <td>471.758594</td>\n",
       "      <td>637.295412</td>\n",
       "      <td>834.061872</td>\n",
       "      <td>1040.614857</td>\n",
       "      <td>1254.607242</td>\n",
       "      <td>1474.502678</td>\n",
       "      <td>1699.23047</td>\n",
       "      <td>1928.009096</td>\n",
       "      <td>2160.247412</td>\n",
       "      <td>2395.485434</td>\n",
       "      <td>2633.356884</td>\n",
       "      <td>2873.564462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89099</th>\n",
       "      <td>471.758594</td>\n",
       "      <td>637.295412</td>\n",
       "      <td>834.061872</td>\n",
       "      <td>1040.614857</td>\n",
       "      <td>1254.607242</td>\n",
       "      <td>1474.502678</td>\n",
       "      <td>1699.23047</td>\n",
       "      <td>1928.009096</td>\n",
       "      <td>2160.247412</td>\n",
       "      <td>2395.485434</td>\n",
       "      <td>2633.356884</td>\n",
       "      <td>2873.564462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          E_c(10)     E_c(100)     E_c(200)     E_c(300)     E_c(400)  \\\n",
       "71300  852.000000  1122.000000  1422.000000  1722.000000  2022.000000   \n",
       "71301  852.000000  1122.000000  1422.000000  1722.000000  2022.000000   \n",
       "71302  852.000000  1122.000000  1422.000000  1722.000000  2022.000000   \n",
       "71303  852.000000  1122.000000  1422.000000  1722.000000  2022.000000   \n",
       "71304  852.000000  1122.000000  1422.000000  1722.000000  2022.000000   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "89095  471.758594   637.295412   834.061872  1040.614857  1254.607242   \n",
       "89096  471.758594   637.295412   834.061872  1040.614857  1254.607242   \n",
       "89097  471.758594   637.295412   834.061872  1040.614857  1254.607242   \n",
       "89098  471.758594   637.295412   834.061872  1040.614857  1254.607242   \n",
       "89099  471.758594   637.295412   834.061872  1040.614857  1254.607242   \n",
       "\n",
       "          E_c(500)    E_c(600)     E_c(700)     E_c(800)     E_c(900)  \\\n",
       "71300  2322.000000  2622.00000  2922.000000  3222.000000  3522.000000   \n",
       "71301  2322.000000  2622.00000  2922.000000  3222.000000  3522.000000   \n",
       "71302  2322.000000  2622.00000  2922.000000  3222.000000  3522.000000   \n",
       "71303  2322.000000  2622.00000  2922.000000  3222.000000  3522.000000   \n",
       "71304  2322.000000  2622.00000  2922.000000  3222.000000  3522.000000   \n",
       "...            ...         ...          ...          ...          ...   \n",
       "89095  1474.502678  1699.23047  1928.009096  2160.247412  2395.485434   \n",
       "89096  1474.502678  1699.23047  1928.009096  2160.247412  2395.485434   \n",
       "89097  1474.502678  1699.23047  1928.009096  2160.247412  2395.485434   \n",
       "89098  1474.502678  1699.23047  1928.009096  2160.247412  2395.485434   \n",
       "89099  1474.502678  1699.23047  1928.009096  2160.247412  2395.485434   \n",
       "\n",
       "         E_c(1000)    E_c(1100)  \n",
       "71300  3822.000000  4122.000000  \n",
       "71301  3822.000000  4122.000000  \n",
       "71302  3822.000000  4122.000000  \n",
       "71303  3822.000000  4122.000000  \n",
       "71304  3822.000000  4122.000000  \n",
       "...            ...          ...  \n",
       "89095  2633.356884  2873.564462  \n",
       "89096  2633.356884  2873.564462  \n",
       "89097  2633.356884  2873.564462  \n",
       "89098  2633.356884  2873.564462  \n",
       "89099  2633.356884  2873.564462  \n",
       "\n",
       "[17800 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED LOG ERROR (MSLE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[0.00621461 0.00261982 0.00249465 0.00270012 0.00284485 0.00291302\n",
      " 0.00292482 0.00290072 0.00285457 0.00279427 0.00272656 0.00265628]\n",
      "Uniform average\n",
      "0.003053691430700206\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED ERROR (MSE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[ 2548.77587576  2541.69645008  3418.54829232  4959.51930575\n",
      "  6995.65272141  9437.3686766  12209.61482549 15259.83421868\n",
      " 18543.61217315 22033.36970829 25695.61883516 29526.09106217]\n",
      "Uniform average\n",
      "12764.141845404638\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Learning curve\n",
      "===================================================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Saving the ANN model info:\n",
      "===================================================================================================================\n",
      "The ANNs model info have been saved in the \"QS_dnn3_enrg_16X_rwsh.pkl\" file !!!\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Building a regression ANN model\n",
    "regression_ANN(\"QS_reg_data_pp8mr8s100_rwshuffled.csv\",mag_reg=\"enrg\",test_ratio=0.2,val_ratio=0.2,samples_per_EOS=100).train_model('no',neurons_enrg_16X,actvs_enrg_16X,drops_enrg_16X,adam_learn_rate=1e-3,train_epochs=1000,batch_size=128,filesave=\"QS_dnn3_enrg_16X_rwsh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16efeb9",
   "metadata": {},
   "source": [
    "## **2.2 Using 16 M-R points**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7748a468",
   "metadata": {},
   "source": [
    "### B. Predicting Energy on center $E_c$ Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7bbb1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists for the neurons, activation functions and dropouts in the layers of the network\n",
    "neurons_enrg_32X = [128,64,32]\n",
    "actvs_enrg_32X = [\"relu\",\"relu\",\"relu\"]\n",
    "drops_enrg_32X = [0.5,0.5,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d799c4",
   "metadata": {},
   "source": [
    "#### ->Using rowwise-shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c42d6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the datasets\n",
    "# regression_ANN(filename=\"QS_reg_data_pp8mr16s100_rwshuffled.csv\",mag_reg=\"enrg\",test_ratio=0.2,val_ratio=0.2,samples_per_EOS=100).show_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "451da594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AND ASSESSING AN ARTIFICIAL NEURAL NETWORK REGRESSION MODEL\n",
      "\n",
      "\n",
      ">Preliminaries\n",
      "===================================================================================================================\n",
      ">> DATA INFO AND SCALING:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Y (response) data type: \"enrg\"\n",
      "Number of Y columns:  12\n",
      "X (explanatory) data type: \"Mass\" and \"Radius\"\n",
      "Number of X columns:  32\n",
      "The scaling of the X (explanatory) data has been completed\n",
      "The scaling of the Y (response) data has been completed\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Compiling and fitting the model\n",
      "===================================================================================================================\n",
      ">> COMPILATION SUMMARY:\n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m396\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,852</span> (61.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,852\u001b[0m (61.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,404</span> (60.17 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,404\u001b[0m (60.17 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> TRAINING:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Ongoing fitting process...\n",
      "Epoch 1/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 45.3164 - val_loss: 28.6157\n",
      "Epoch 2/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 26.9799 - val_loss: 18.3187\n",
      "Epoch 3/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 17.7611 - val_loss: 14.3642\n",
      "Epoch 4/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 13.6536 - val_loss: 11.5273\n",
      "Epoch 5/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 11.0940 - val_loss: 9.5935\n",
      "Epoch 6/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 9.2836 - val_loss: 8.0983\n",
      "Epoch 7/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7.8104 - val_loss: 6.8289\n",
      "Epoch 8/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6.6304 - val_loss: 5.8756\n",
      "Epoch 9/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.5935 - val_loss: 5.0534\n",
      "Epoch 10/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4.7951 - val_loss: 4.3420\n",
      "Epoch 11/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4.1125 - val_loss: 3.7280\n",
      "Epoch 12/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3.5308 - val_loss: 3.2052\n",
      "Epoch 13/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3.0369 - val_loss: 2.7504\n",
      "Epoch 14/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.6053 - val_loss: 2.3543\n",
      "Epoch 15/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.2297 - val_loss: 2.0130\n",
      "Epoch 16/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.8939 - val_loss: 1.7223\n",
      "Epoch 17/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.6159 - val_loss: 1.4538\n",
      "Epoch 18/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.3651 - val_loss: 1.2249\n",
      "Epoch 19/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.1564 - val_loss: 1.0347\n",
      "Epoch 20/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9742 - val_loss: 0.8638\n",
      "Epoch 21/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.8115 - val_loss: 0.7261\n",
      "Epoch 22/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6718 - val_loss: 0.6049\n",
      "Epoch 23/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.5578 - val_loss: 0.4961\n",
      "Epoch 24/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4621 - val_loss: 0.4745\n",
      "Epoch 25/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3796 - val_loss: 0.3227\n",
      "Epoch 26/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3034 - val_loss: 0.2618\n",
      "Epoch 27/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2437 - val_loss: 0.2109\n",
      "Epoch 28/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1936 - val_loss: 0.1657\n",
      "Epoch 29/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1523 - val_loss: 0.1298\n",
      "Epoch 30/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1206 - val_loss: 0.1015\n",
      "Epoch 31/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0935 - val_loss: 0.0771\n",
      "Epoch 32/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0714 - val_loss: 0.0582\n",
      "Epoch 33/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0548 - val_loss: 0.0440\n",
      "Epoch 34/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0414 - val_loss: 0.0333\n",
      "Epoch 35/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0325 - val_loss: 0.0241\n",
      "Epoch 36/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0238 - val_loss: 0.0176\n",
      "Epoch 37/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0181 - val_loss: 0.0131\n",
      "Epoch 38/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0146 - val_loss: 0.0094\n",
      "Epoch 39/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0109 - val_loss: 0.0068\n",
      "Epoch 40/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 41/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0069 - val_loss: 0.0039\n",
      "Epoch 42/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 43/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 44/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 45/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0044 - val_loss: 0.0020\n",
      "Epoch 46/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 47/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 48/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 49/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 50/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 51/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 52/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 53/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 54/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 55/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 56/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 57/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 58/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 59/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 60/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 61/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 62/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 63/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 64/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 65/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 66/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 67/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 68/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 69/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 70/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 71/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 72/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 73/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 74/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 75/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 76/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 77/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 78/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 79/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 80/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 81/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 82/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 83/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 84/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 85/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 86/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 87/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 88/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 89/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 90/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 91/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 92/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 93/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 94/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 95/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 96/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 97/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 98/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 99/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 100/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 101/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 102/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 103/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 104/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 105/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 106/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 107/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 108/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 109/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 110/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 111/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 112/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 113/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 114/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 115/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 116/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 117/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 118/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 119/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 120/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 121/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 122/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 123/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 124/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 125/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 126/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 127/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 128/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 129/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 130/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 131/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 132/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 133/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 134/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 135/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 136/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 137/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 138/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 139/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 140/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 141/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 142/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 143/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 144/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 145/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 146/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 147/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 148/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 149/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 150/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 151/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 152/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 153/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 154/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 155/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 156/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 157/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 158/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 159/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 160/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 161/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 162/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 163/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 164/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 165/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 166/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 167/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 168/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 169/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 170/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 171/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 172/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 173/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 174/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 175/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 176/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 177/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 178/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 179/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 180/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 181/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 182/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 183/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 184/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 185/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 186/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 187/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 188/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 189/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 190/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 191/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 192/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 193/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 194/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 195/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 196/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 197/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 198/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 199/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 200/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 201/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 202/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 203/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 204/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 205/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 206/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 207/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 208/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 209/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 210/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 211/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 212/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 213/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 214/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 215/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 216/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 217/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 218/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 219/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 220/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 221/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 222/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 223/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 224/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 225/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 226/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 227/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 228/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 229/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 230/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 231/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 232/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 233/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 234/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 235/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 236/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 237/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 238/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 239/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 240/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 241/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 242/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 243/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 244/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 245/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 246/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 247/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 248/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 249/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 250/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 251/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 252/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 253/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 254/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 255/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 256/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 257/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 258/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 259/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 260/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 261/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 262/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 263/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 264/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 265/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 266/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 267/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 268/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 269/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 270/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 271/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 272/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 273/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 274/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 275/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 276/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 277/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 278/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 279/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 280/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 281/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 282/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 283/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 284/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 285/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 286/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 287/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 288/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 289/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 290/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 291/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 292/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 293/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 294/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 295/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 296/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 297/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 298/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 299/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 300/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 301/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 302/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 303/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 304/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 305/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 306/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 307/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 308/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 309/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 310/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 311/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 312/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 313/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 314/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 315/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 316/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 317/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 318/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 319/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 320/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 321/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 322/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 323/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 324/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 325/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 326/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 327/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 328/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 329/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 330/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 331/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 332/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 333/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 334/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 335/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 336/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 337/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 338/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 339/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 340/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 341/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 342/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 343/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 344/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 345/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 346/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 347/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 348/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 349/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 350/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 351/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 352/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 353/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 354/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 355/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 356/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 357/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 358/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 359/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 360/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 361/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 362/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 363/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 364/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 365/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 366/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 367/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 368/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 369/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 370/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 371/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 372/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 373/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 374/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 375/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 376/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 377/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 378/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 379/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 380/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 381/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 382/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 383/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 384/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 385/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 386/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 387/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 388/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 389/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 390/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 391/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 392/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 393/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 394/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 395/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 396/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 397/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 398/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 399/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 400/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 401/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 402/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 403/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 404/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 405/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 406/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 407/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 408/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 409/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 410/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 411/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 412/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 413/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 414/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 415/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 416/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 417/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 418/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 419/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 420/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 421/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 422/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 423/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 424/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 425/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 426/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 427/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 428/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 429/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 430/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 431/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 432/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 433/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 434/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 435/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 436/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 437/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 438/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 439/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 440/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 441/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 442/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 443/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 444/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 445/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 446/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 447/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 448/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 449/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 450/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 451/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 452/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 453/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 454/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 455/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 456/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 457/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 458/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 459/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 460/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 461/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 462/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 463/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 464/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 465/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 466/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 467/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 468/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 469/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 470/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 471/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 472/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 473/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 474/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 475/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 476/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 477/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 478/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 479/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 480/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 481/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 482/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 483/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 484/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 485/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 486/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 487/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 488/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 489/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 490/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 491/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 492/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 493/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 494/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 495/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 496/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 497/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 498/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 499/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 500/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 501/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 502/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 503/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 504/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 505/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 506/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 507/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 508/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 509/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 510/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 511/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 512/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 513/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 514/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 515/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 516/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 517/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 518/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 519/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 520/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 521/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 522/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 523/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 524/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 525/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 526/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 527/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 528/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 529/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 530/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 531/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 532/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 533/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 534/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 535/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 536/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 537/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 538/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 539/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 540/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 541/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 542/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 543/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 544/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 545/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 546/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 547/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 548/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 549/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 550/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 551/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 552/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 553/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 554/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 555/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 556/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 557/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 558/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 559/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 560/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 561/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 562/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 563/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 564/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 565/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 566/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 567/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 568/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 569/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 570/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 571/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 572/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 573/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 574/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 575/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 576/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 577/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 578/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 579/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 580/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 581/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 582/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 583/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 584/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 585/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 586/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 587/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 588/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 589/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 590/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 591/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 592/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 593/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 594/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 595/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 596/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 597/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 598/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 599/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 600/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 601/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 602/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 603/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 604/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 605/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 606/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 607/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 608/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 609/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 610/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 611/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 612/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 613/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 614/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 615/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 616/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 617/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 618/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 619/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 620/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 621/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 622/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 623/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 624/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 625/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 626/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 627/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 628/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 629/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 630/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 631/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 632/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 633/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 634/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 635/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 636/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 637/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 638/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 639/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 640/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 641/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 642/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 643/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 644/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 645/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 646/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 647/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 648/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 649/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 650/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 651/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 652/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 653/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 654/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 655/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 656/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 657/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 658/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 659/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 660/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 661/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 662/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 663/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 664/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 665/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 666/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 667/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 668/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 669/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 670/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 671/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 672/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 673/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 674/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 675/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 676/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 677/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 678/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 679/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 680/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 681/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 682/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 683/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 684/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 685/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 686/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 687/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 688/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 689/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 690/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 691/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 692/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 693/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 694/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 695/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 696/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 697/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 698/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 699/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 700/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 701/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 702/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 703/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 704/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 705/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 706/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 707/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 708/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 709/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 710/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 711/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 712/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 713/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 714/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 715/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 716/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 717/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 718/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 719/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 720/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 721/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 722/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 723/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 724/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 725/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 726/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 727/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 728/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 729/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 730/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 731/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 732/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 733/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 734/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 735/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 736/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 737/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 738/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 739/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 740/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 741/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 742/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 743/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 744/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 745/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 746/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 747/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 748/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 749/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 750/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 751/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 752/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 753/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 754/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 755/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 756/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 757/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 758/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 759/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 760/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 761/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 762/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 763/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 764/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 765/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 766/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 767/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 768/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 769/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 770/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 771/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 772/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 773/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 774/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 775/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 776/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 777/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 778/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 779/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 780/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 781/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 782/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 783/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 784/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 785/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 786/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 787/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 788/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 789/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 790/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 791/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 792/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 793/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 794/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 795/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 796/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 797/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 798/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 799/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 800/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 801/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 802/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 803/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 804/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 805/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 806/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 807/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 808/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 809/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 810/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 811/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 812/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 813/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 814/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 815/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 816/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 817/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 818/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 819/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 820/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 821/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 822/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 823/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 824/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 825/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 826/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 827/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 828/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 829/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 830/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 831/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 832/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 833/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 834/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 835/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 836/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 837/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 838/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 839/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 840/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 841/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 842/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 843/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 844/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 845/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 846/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 847/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 848/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 849/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 850/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 851/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 852/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 853/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 854/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 855/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 856/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 857/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 858/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 859/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 860/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 861/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 862/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 863/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 864/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 865/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 866/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 867/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 868/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 869/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 870/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 871/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 872/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 873/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 874/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 875/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 876/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 877/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 878/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 879/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 880/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 881/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 882/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 883/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 884/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 885/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 886/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 887/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 888/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 889/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 890/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 891/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 892/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 893/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 894/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 895/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 896/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 897/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 898/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 899/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 900/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 901/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 902/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 903/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 904/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 905/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 906/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 907/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 908/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 909/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 910/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 911/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 912/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 913/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 914/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 915/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 916/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 917/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 918/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 919/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 920/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 921/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 922/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 923/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 924/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 925/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 926/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 927/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 928/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 929/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 930/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 931/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 932/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 933/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 934/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 935/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 936/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 937/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 938/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 939/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 940/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 941/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 942/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 943/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 944/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 945/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 946/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 947/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 948/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 949/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 950/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 951/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 952/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 953/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 954/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 955/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 956/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 957/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 958/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 959/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 960/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 961/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 962/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 963/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 964/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 965/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 966/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 967/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 968/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 969/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 970/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 971/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 972/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 973/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 974/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 975/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 976/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 977/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 978/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 979/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 980/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 981/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 982/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 983/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 984/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 985/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 986/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 987/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 988/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 989/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 990/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 991/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 992/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 993/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 994/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 995/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 996/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 997/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 998/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 999/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 1000/1000\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
      "The fitting process has been completed\n",
      "Elapsed fitting time: 12.0'37.56\"\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Overfitting metrics (using the train dataset as test dataset)\n",
      "===================================================================================================================\n",
      ">> PREDICTIONS AND REAL VALUES:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m1782/1782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step\n",
      "Predictions of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 527.18695,  744.69904,  993.4172 , ..., 2831.4614 , 3101.8345 ,\n",
       "        3372.9988 ],\n",
       "       [ 500.09335,  762.0783 , 1053.818  , ..., 3110.4792 , 3405.9417 ,\n",
       "        3701.0305 ],\n",
       "       [ 510.24423,  772.93726, 1065.3927 , ..., 3126.4187 , 3422.4958 ,\n",
       "        3718.151  ],\n",
       "       ...,\n",
       "       [ 206.43391,  367.10626,  566.2009 , ..., 2181.1172 , 2427.4175 ,\n",
       "        2675.8357 ],\n",
       "       [ 217.98145,  378.32852,  576.4674 , ..., 2184.0564 , 2429.407  ,\n",
       "        2676.9165 ],\n",
       "       [ 200.52614,  359.04654,  555.9237 , ..., 2159.284  , 2404.232  ,\n",
       "        2651.36   ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_c(10)</th>\n",
       "      <th>E_c(100)</th>\n",
       "      <th>E_c(200)</th>\n",
       "      <th>E_c(300)</th>\n",
       "      <th>E_c(400)</th>\n",
       "      <th>E_c(500)</th>\n",
       "      <th>E_c(600)</th>\n",
       "      <th>E_c(700)</th>\n",
       "      <th>E_c(800)</th>\n",
       "      <th>E_c(900)</th>\n",
       "      <th>E_c(1000)</th>\n",
       "      <th>E_c(1100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>498.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1368.000000</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>2568.00000</td>\n",
       "      <td>2868.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3468.000000</td>\n",
       "      <td>3768.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>498.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1368.000000</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>2568.00000</td>\n",
       "      <td>2868.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3468.000000</td>\n",
       "      <td>3768.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>498.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1368.000000</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>2568.00000</td>\n",
       "      <td>2868.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3468.000000</td>\n",
       "      <td>3768.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>498.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1368.000000</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>2568.00000</td>\n",
       "      <td>2868.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3468.000000</td>\n",
       "      <td>3768.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>498.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>1068.000000</td>\n",
       "      <td>1368.000000</td>\n",
       "      <td>1668.000000</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>2268.000000</td>\n",
       "      <td>2568.00000</td>\n",
       "      <td>2868.000000</td>\n",
       "      <td>3168.000000</td>\n",
       "      <td>3468.000000</td>\n",
       "      <td>3768.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56995</th>\n",
       "      <td>215.446869</td>\n",
       "      <td>374.558577</td>\n",
       "      <td>571.504921</td>\n",
       "      <td>781.695495</td>\n",
       "      <td>1001.046783</td>\n",
       "      <td>1227.222158</td>\n",
       "      <td>1458.736193</td>\n",
       "      <td>1694.57501</td>\n",
       "      <td>1934.010026</td>\n",
       "      <td>2176.496809</td>\n",
       "      <td>2421.615832</td>\n",
       "      <td>2669.0357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56996</th>\n",
       "      <td>215.446869</td>\n",
       "      <td>374.558577</td>\n",
       "      <td>571.504921</td>\n",
       "      <td>781.695495</td>\n",
       "      <td>1001.046783</td>\n",
       "      <td>1227.222158</td>\n",
       "      <td>1458.736193</td>\n",
       "      <td>1694.57501</td>\n",
       "      <td>1934.010026</td>\n",
       "      <td>2176.496809</td>\n",
       "      <td>2421.615832</td>\n",
       "      <td>2669.0357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56997</th>\n",
       "      <td>215.446869</td>\n",
       "      <td>374.558577</td>\n",
       "      <td>571.504921</td>\n",
       "      <td>781.695495</td>\n",
       "      <td>1001.046783</td>\n",
       "      <td>1227.222158</td>\n",
       "      <td>1458.736193</td>\n",
       "      <td>1694.57501</td>\n",
       "      <td>1934.010026</td>\n",
       "      <td>2176.496809</td>\n",
       "      <td>2421.615832</td>\n",
       "      <td>2669.0357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56998</th>\n",
       "      <td>215.446869</td>\n",
       "      <td>374.558577</td>\n",
       "      <td>571.504921</td>\n",
       "      <td>781.695495</td>\n",
       "      <td>1001.046783</td>\n",
       "      <td>1227.222158</td>\n",
       "      <td>1458.736193</td>\n",
       "      <td>1694.57501</td>\n",
       "      <td>1934.010026</td>\n",
       "      <td>2176.496809</td>\n",
       "      <td>2421.615832</td>\n",
       "      <td>2669.0357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56999</th>\n",
       "      <td>215.446869</td>\n",
       "      <td>374.558577</td>\n",
       "      <td>571.504921</td>\n",
       "      <td>781.695495</td>\n",
       "      <td>1001.046783</td>\n",
       "      <td>1227.222158</td>\n",
       "      <td>1458.736193</td>\n",
       "      <td>1694.57501</td>\n",
       "      <td>1934.010026</td>\n",
       "      <td>2176.496809</td>\n",
       "      <td>2421.615832</td>\n",
       "      <td>2669.0357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          E_c(10)    E_c(100)     E_c(200)     E_c(300)     E_c(400)  \\\n",
       "0      498.000000  768.000000  1068.000000  1368.000000  1668.000000   \n",
       "1      498.000000  768.000000  1068.000000  1368.000000  1668.000000   \n",
       "2      498.000000  768.000000  1068.000000  1368.000000  1668.000000   \n",
       "3      498.000000  768.000000  1068.000000  1368.000000  1668.000000   \n",
       "4      498.000000  768.000000  1068.000000  1368.000000  1668.000000   \n",
       "...           ...         ...          ...          ...          ...   \n",
       "56995  215.446869  374.558577   571.504921   781.695495  1001.046783   \n",
       "56996  215.446869  374.558577   571.504921   781.695495  1001.046783   \n",
       "56997  215.446869  374.558577   571.504921   781.695495  1001.046783   \n",
       "56998  215.446869  374.558577   571.504921   781.695495  1001.046783   \n",
       "56999  215.446869  374.558577   571.504921   781.695495  1001.046783   \n",
       "\n",
       "          E_c(500)     E_c(600)    E_c(700)     E_c(800)     E_c(900)  \\\n",
       "0      1968.000000  2268.000000  2568.00000  2868.000000  3168.000000   \n",
       "1      1968.000000  2268.000000  2568.00000  2868.000000  3168.000000   \n",
       "2      1968.000000  2268.000000  2568.00000  2868.000000  3168.000000   \n",
       "3      1968.000000  2268.000000  2568.00000  2868.000000  3168.000000   \n",
       "4      1968.000000  2268.000000  2568.00000  2868.000000  3168.000000   \n",
       "...            ...          ...         ...          ...          ...   \n",
       "56995  1227.222158  1458.736193  1694.57501  1934.010026  2176.496809   \n",
       "56996  1227.222158  1458.736193  1694.57501  1934.010026  2176.496809   \n",
       "56997  1227.222158  1458.736193  1694.57501  1934.010026  2176.496809   \n",
       "56998  1227.222158  1458.736193  1694.57501  1934.010026  2176.496809   \n",
       "56999  1227.222158  1458.736193  1694.57501  1934.010026  2176.496809   \n",
       "\n",
       "         E_c(1000)  E_c(1100)  \n",
       "0      3468.000000  3768.0000  \n",
       "1      3468.000000  3768.0000  \n",
       "2      3468.000000  3768.0000  \n",
       "3      3468.000000  3768.0000  \n",
       "4      3468.000000  3768.0000  \n",
       "...            ...        ...  \n",
       "56995  2421.615832  2669.0357  \n",
       "56996  2421.615832  2669.0357  \n",
       "56997  2421.615832  2669.0357  \n",
       "56998  2421.615832  2669.0357  \n",
       "56999  2421.615832  2669.0357  \n",
       "\n",
       "[57000 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED LOG ERROR (MSLE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[0.00339674 0.00110768 0.00114128 0.00137197 0.00154218 0.00164325\n",
      " 0.00169492 0.00171233 0.00170944 0.00169208 0.00166645 0.00163596]\n",
      "Uniform average\n",
      "0.00169285702693544\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED ERROR (MSE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[ 1264.82496156  1014.80456553  1358.82581507  2162.40844616\n",
      "  3324.69608073  4767.64743773  6448.12010032  8317.83355161\n",
      " 10366.79894946 12554.48615211 14874.92898879 17320.56009103]\n",
      "Uniform average\n",
      "6981.327928340684\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Prediction metrics (using the actual test dataset)\n",
      "===================================================================================================================\n",
      ">> PREDICTIONS AND REAL VALUES:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step\n",
      "Predictions of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 764.76935, 1034.4447 , 1334.132  , ..., 3432.9253 , 3734.305  ,\n",
       "        4033.9822 ],\n",
       "       [ 840.2695 , 1112.3043 , 1413.1362 , ..., 3527.3015 , 3832.1392 ,\n",
       "        4134.0938 ],\n",
       "       [ 813.0944 , 1085.3594 , 1386.7417 , ..., 3499.2144 , 3803.0205 ,\n",
       "        4104.563  ],\n",
       "       ...,\n",
       "       [ 446.8039 ,  636.4159 ,  856.9431 , ..., 2551.587  , 2805.6567 ,\n",
       "        3061.6147 ],\n",
       "       [ 447.30435,  629.44495,  841.8489 , ..., 2492.8926 , 2742.0627 ,\n",
       "        2993.1848 ],\n",
       "       [ 419.4835 ,  599.185  ,  809.5144 , ..., 2452.741  , 2701.3276 ,\n",
       "        2951.735  ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual values of \"enrg\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_c(10)</th>\n",
       "      <th>E_c(100)</th>\n",
       "      <th>E_c(200)</th>\n",
       "      <th>E_c(300)</th>\n",
       "      <th>E_c(400)</th>\n",
       "      <th>E_c(500)</th>\n",
       "      <th>E_c(600)</th>\n",
       "      <th>E_c(700)</th>\n",
       "      <th>E_c(800)</th>\n",
       "      <th>E_c(900)</th>\n",
       "      <th>E_c(1000)</th>\n",
       "      <th>E_c(1100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71300</th>\n",
       "      <td>852.000000</td>\n",
       "      <td>1122.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1722.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2322.000000</td>\n",
       "      <td>2622.00000</td>\n",
       "      <td>2922.000000</td>\n",
       "      <td>3222.000000</td>\n",
       "      <td>3522.000000</td>\n",
       "      <td>3822.000000</td>\n",
       "      <td>4122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71301</th>\n",
       "      <td>852.000000</td>\n",
       "      <td>1122.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1722.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2322.000000</td>\n",
       "      <td>2622.00000</td>\n",
       "      <td>2922.000000</td>\n",
       "      <td>3222.000000</td>\n",
       "      <td>3522.000000</td>\n",
       "      <td>3822.000000</td>\n",
       "      <td>4122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71302</th>\n",
       "      <td>852.000000</td>\n",
       "      <td>1122.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1722.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2322.000000</td>\n",
       "      <td>2622.00000</td>\n",
       "      <td>2922.000000</td>\n",
       "      <td>3222.000000</td>\n",
       "      <td>3522.000000</td>\n",
       "      <td>3822.000000</td>\n",
       "      <td>4122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71303</th>\n",
       "      <td>852.000000</td>\n",
       "      <td>1122.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1722.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2322.000000</td>\n",
       "      <td>2622.00000</td>\n",
       "      <td>2922.000000</td>\n",
       "      <td>3222.000000</td>\n",
       "      <td>3522.000000</td>\n",
       "      <td>3822.000000</td>\n",
       "      <td>4122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71304</th>\n",
       "      <td>852.000000</td>\n",
       "      <td>1122.000000</td>\n",
       "      <td>1422.000000</td>\n",
       "      <td>1722.000000</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>2322.000000</td>\n",
       "      <td>2622.00000</td>\n",
       "      <td>2922.000000</td>\n",
       "      <td>3222.000000</td>\n",
       "      <td>3522.000000</td>\n",
       "      <td>3822.000000</td>\n",
       "      <td>4122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89095</th>\n",
       "      <td>471.758594</td>\n",
       "      <td>637.295412</td>\n",
       "      <td>834.061872</td>\n",
       "      <td>1040.614857</td>\n",
       "      <td>1254.607242</td>\n",
       "      <td>1474.502678</td>\n",
       "      <td>1699.23047</td>\n",
       "      <td>1928.009096</td>\n",
       "      <td>2160.247412</td>\n",
       "      <td>2395.485434</td>\n",
       "      <td>2633.356884</td>\n",
       "      <td>2873.564462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89096</th>\n",
       "      <td>471.758594</td>\n",
       "      <td>637.295412</td>\n",
       "      <td>834.061872</td>\n",
       "      <td>1040.614857</td>\n",
       "      <td>1254.607242</td>\n",
       "      <td>1474.502678</td>\n",
       "      <td>1699.23047</td>\n",
       "      <td>1928.009096</td>\n",
       "      <td>2160.247412</td>\n",
       "      <td>2395.485434</td>\n",
       "      <td>2633.356884</td>\n",
       "      <td>2873.564462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89097</th>\n",
       "      <td>471.758594</td>\n",
       "      <td>637.295412</td>\n",
       "      <td>834.061872</td>\n",
       "      <td>1040.614857</td>\n",
       "      <td>1254.607242</td>\n",
       "      <td>1474.502678</td>\n",
       "      <td>1699.23047</td>\n",
       "      <td>1928.009096</td>\n",
       "      <td>2160.247412</td>\n",
       "      <td>2395.485434</td>\n",
       "      <td>2633.356884</td>\n",
       "      <td>2873.564462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89098</th>\n",
       "      <td>471.758594</td>\n",
       "      <td>637.295412</td>\n",
       "      <td>834.061872</td>\n",
       "      <td>1040.614857</td>\n",
       "      <td>1254.607242</td>\n",
       "      <td>1474.502678</td>\n",
       "      <td>1699.23047</td>\n",
       "      <td>1928.009096</td>\n",
       "      <td>2160.247412</td>\n",
       "      <td>2395.485434</td>\n",
       "      <td>2633.356884</td>\n",
       "      <td>2873.564462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89099</th>\n",
       "      <td>471.758594</td>\n",
       "      <td>637.295412</td>\n",
       "      <td>834.061872</td>\n",
       "      <td>1040.614857</td>\n",
       "      <td>1254.607242</td>\n",
       "      <td>1474.502678</td>\n",
       "      <td>1699.23047</td>\n",
       "      <td>1928.009096</td>\n",
       "      <td>2160.247412</td>\n",
       "      <td>2395.485434</td>\n",
       "      <td>2633.356884</td>\n",
       "      <td>2873.564462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          E_c(10)     E_c(100)     E_c(200)     E_c(300)     E_c(400)  \\\n",
       "71300  852.000000  1122.000000  1422.000000  1722.000000  2022.000000   \n",
       "71301  852.000000  1122.000000  1422.000000  1722.000000  2022.000000   \n",
       "71302  852.000000  1122.000000  1422.000000  1722.000000  2022.000000   \n",
       "71303  852.000000  1122.000000  1422.000000  1722.000000  2022.000000   \n",
       "71304  852.000000  1122.000000  1422.000000  1722.000000  2022.000000   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "89095  471.758594   637.295412   834.061872  1040.614857  1254.607242   \n",
       "89096  471.758594   637.295412   834.061872  1040.614857  1254.607242   \n",
       "89097  471.758594   637.295412   834.061872  1040.614857  1254.607242   \n",
       "89098  471.758594   637.295412   834.061872  1040.614857  1254.607242   \n",
       "89099  471.758594   637.295412   834.061872  1040.614857  1254.607242   \n",
       "\n",
       "          E_c(500)    E_c(600)     E_c(700)     E_c(800)     E_c(900)  \\\n",
       "71300  2322.000000  2622.00000  2922.000000  3222.000000  3522.000000   \n",
       "71301  2322.000000  2622.00000  2922.000000  3222.000000  3522.000000   \n",
       "71302  2322.000000  2622.00000  2922.000000  3222.000000  3522.000000   \n",
       "71303  2322.000000  2622.00000  2922.000000  3222.000000  3522.000000   \n",
       "71304  2322.000000  2622.00000  2922.000000  3222.000000  3522.000000   \n",
       "...            ...         ...          ...          ...          ...   \n",
       "89095  1474.502678  1699.23047  1928.009096  2160.247412  2395.485434   \n",
       "89096  1474.502678  1699.23047  1928.009096  2160.247412  2395.485434   \n",
       "89097  1474.502678  1699.23047  1928.009096  2160.247412  2395.485434   \n",
       "89098  1474.502678  1699.23047  1928.009096  2160.247412  2395.485434   \n",
       "89099  1474.502678  1699.23047  1928.009096  2160.247412  2395.485434   \n",
       "\n",
       "         E_c(1000)    E_c(1100)  \n",
       "71300  3822.000000  4122.000000  \n",
       "71301  3822.000000  4122.000000  \n",
       "71302  3822.000000  4122.000000  \n",
       "71303  3822.000000  4122.000000  \n",
       "71304  3822.000000  4122.000000  \n",
       "...            ...          ...  \n",
       "89095  2633.356884  2873.564462  \n",
       "89096  2633.356884  2873.564462  \n",
       "89097  2633.356884  2873.564462  \n",
       "89098  2633.356884  2873.564462  \n",
       "89099  2633.356884  2873.564462  \n",
       "\n",
       "[17800 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED LOG ERROR (MSLE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[0.00340211 0.00112784 0.00116822 0.00139821 0.00156658 0.00166548\n",
      " 0.00171526 0.00173077 0.00172666 0.00170798 0.00168111 0.00164982]\n",
      "Uniform average\n",
      "0.001711669429184091\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      ">> MEAN SQUARED ERROR (MSE) RESULTS:\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Raw values\n",
      "[ 1330.28790967  1078.28700929  1428.09103742  2240.85308312\n",
      "  3416.1101687   4872.54992719  6568.49164354  8453.03352724\n",
      " 10520.07865789 12724.55971741 15061.73463689 17526.85478617]\n",
      "Uniform average\n",
      "7101.744342043832\n",
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Learning curve\n",
      "===================================================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================\n",
      "\n",
      "\n",
      "\n",
      ">Saving the ANN model info:\n",
      "===================================================================================================================\n",
      "The ANNs model info have been saved in the \"QS_dnn3_enrg_32X_rwsh.pkl\" file !!!\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Building a regression ANN model\n",
    "regression_ANN(\"QS_reg_data_pp8mr16s100_rwshuffled.csv\",mag_reg=\"enrg\",test_ratio=0.2,val_ratio=0.2,samples_per_EOS=100).train_model(\"no\",neurons_enrg_32X,actvs_enrg_32X,drops_enrg_32X,adam_learn_rate=1e-3,train_epochs=1000,batch_size=128,filesave=\"QS_dnn3_enrg_32X_rwsh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000730a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
